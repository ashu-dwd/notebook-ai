**Overall Review Summary:**
- **Total Issues Found:** 7
- **Critical Issues:** 3 (Missing `await` for DB calls, Untrapped Errors, Data Inconsistency)
- **Code Quality Score:** 6/10
- **Approval Status:** NEEDS_CHANGES
- **Key Recommendations:**
    1.  Ensure all asynchronous database operations (`runQuery`) are properly `await`ed and within a `try...catch` block to prevent unhandled promise rejections and logical errors.
    2.  Implement transactional integrity or batch operations for database writes that involve multiple records or dependencies (e.g., file metadata linked to vectors) to guarantee data consistency and improve performance.
    3.  Refactor SQL queries out of controller logic into a dedicated data access layer (e.g., repositories) for better separation of concerns, maintainability, and testability.

---

### File-by-File Review

**File:** `server/src/controllers/upload.controller.js`

**Line(s):** 4, 8
- **Issue Type:** STYLE
  **Description:** The `uuidv4` import is duplicated. It's imported once on line 4 and again on line 8, which is redundant.
  **Line(s) to Fix:** 8
  **Current Code:**
  ```javascript
  import { chunkPdf } from "../services/langchain.service.js";
  import { getEmbeddings } from "../services/llm.service.js";
  import { v4 as uuidv4 } from "uuid";
  import { addVector } from "../services/chromadb.service.js";
  import { logger } from "../utils/logger.js";
  import ApiError from "../utils/ApiError.js";
  import { db, runQuery } from "../database/sqlLite.db.js";
  import { v4 as uuidv4 } from "uuid"; // <--- Duplicated
  ```
  **Suggested Fix:**
  ```javascript
  import { chunkPdf } from "../services/langchain.service.js";
  import { getEmbeddings } from "../services/llm.service.js";
  import { v4 as uuidv4 } from "uuid"; // Keep this one
  import { addVector } from "../services/chromadb.service.js";
  import { logger } from "../utils/logger.js";
  import ApiError from "../utils/ApiError.js";
  import { db, runQuery } from "../database/sqlLite.db.js";
  // Remove the duplicate import on line 8
  ```
  **Priority:** MINOR

**Line(s):** 11-14
- **Issue Type:** BUG / LOGIC / ERROR_HANDLING
  **Description:** The `runQuery` call to retrieve the user (`const user = runQuery(...)`) is missing an `await` keyword. Since `runQuery` likely returns a Promise, `user` will hold a Promise object, not the resolved user data. This leads to two critical issues:
    1.  The `if (!user)` check on line 21 will incorrectly pass (as a Promise object is truthy), allowing execution to continue with an unresolved Promise instead of actual user data.
    2.  Accessing `user.userId` later will result in a runtime error because `userId` property does not exist on a Promise.
    3.  This database operation is outside the `try...catch` block, meaning any error thrown by `runQuery` will be unhandled, potentially crashing the application.
  **Line(s) to Fix:** 11-14
  **Current Code:**
  ```javascript
  export const handlePdfUpload = async (req, res) => {
    //console.log("üìÇ Uploaded File:", req.file);
    const user = runQuery("SELECT userId FROM userData WHERE email = ? LIMIT 1", [
      req.user.email,
    ]);
    console.log("User found:", user);
    try {
      logger.info("Uploaded file:", req.file);
      // ... (rest of the try block)
    } catch (error) { /* ... */ }
  };
  ```
  **Suggested Fix:**
  ```javascript
  export const handlePdfUpload = async (req, res) => {
    // ‚ö†Ô∏è Move initial DB call inside the try...catch block
    try {
      logger.info("Uploaded file:", req.file);

      // 1Ô∏è‚É£ Get userId from email - MUST be awaited
      const user = await runQuery("SELECT userId FROM userData WHERE email = ? LIMIT 1", [
        req.user.email,
      ]);

      // Assuming runQuery for SELECT returns the row object directly or null/undefined
      // if no row found. If it returns an array, adjust the check: `if (!user || user.length === 0)`
      if (!user || !user.userId) { // Added !user.userId for robustness
        throw new ApiError(404, "User not found", [req.user.email]);
      }
      logger.info("User found:", user); // Moved console.log to logger.info

      // ... rest of the try block
    } catch (error) {
      // ... (existing error handling)
    }
  };
  ```
  **Priority:** HIGH

**Line(s):** 15, 44
- **Issue Type:** STYLE
  **Description:** `console.log` statements are used for debugging or informational logging. In a production environment, these should be replaced with the `logger` utility for consistent, configurable, and production-ready logging.
  **Line(s) to Fix:** 15, 44
  **Current Code:**
  ```javascript
  console.log("User found:", user);
  // ...
  console.log("üß© Vector inserted with ID:", vectorResult.id);
  ```
  **Suggested Fix:**
  ```javascript
  logger.info("User found:", user);
  // ...
  logger.info("üß© Vector inserted with ID:", vectorResult.id);
  ```
  **Priority:** MEDIUM

**Line(s):** 49-53
- **Issue Type:** BUG / DATA_CONSISTENCY / ERROR_HANDLING
  **Description:** The `runQuery` call for inserting file metadata into SQLite is missing an `await` keyword. This makes the database operation a "fire and forget" call within the `pages.map`'s `async` function. Although `Promise.all` waits for the mapped promises to resolve, if the promises *within* those mapped functions aren't awaited, it leads to:
    1.  **Untrapped Errors:** Any error thrown by this `runQuery` will not be caught by the surrounding `try...catch` block (or by the `Promise.all` error handling), resulting in an unhandled promise rejection and a potential application crash or silent failure.
    2.  **Data Inconsistency:** The database write might not complete before the overall `handlePdfUpload` function finishes and responds, leading to a state where vectors are in ChromaDB but their corresponding metadata is missing or delayed in SQLite.
  **Line(s) to Fix:** 49-53
  **Current Code:**
  ```javascript
        const chatId = uuidv4();
        runQuery( // <--- Missing await
          `
    INSERT INTO files (userId, filePath, vectorId, chatId)
    VALUES (?, ?, ?, ?)
  `,
          [user.userId, req.file.path, vectorResult.id, chatId]
        );
        // console.log("‚úÖ File inserted with ID:", fileInsert.lastInsertRowid);
        return vectorResult.id;
      })
    );
  ```
  **Suggested Fix:**
  ```javascript
        const chatId = uuidv4();
        await runQuery( // <--- Add await here
          `
    INSERT INTO files (userId, filePath, vectorId, chatId)
    VALUES (?, ?, ?, ?)
  `,
          [user.userId, req.file.path, vectorResult.id, chatId]
        );
        // console.log("‚úÖ File inserted with ID:", fileInsert.lastInsertRowid);
        return vectorResult.id;
      })
    );
  ```
  **Priority:** HIGH

**Line(s):** 30-58 (within `pages.map` loop)
- **Issue Type:** PERFORMANCE / DATA_CONSISTENCY / MAINTAINABILITY
  **Description:** The code performs an `addVector` operation to ChromaDB and then a separate `runQuery` for SQLite *for each page individually* inside the `Promise.all` loop.
    1.  **Performance:** Running `N` separate `INSERT` statements for `N` pages can be significantly slower than a single batch insert or a transaction if the database supports it. Each `runQuery` often incurs overhead (e.g., connection acquisition, statement preparation, individual transaction commit).
    2.  **Atomicity/Data Consistency:** If `addVector` succeeds for a page but the subsequent `runQuery` for SQLite fails (e.g., due to a unique constraint violation, database error, or network issue), you will have orphaned vectors in ChromaDB without corresponding entries in your SQLite `files` table. This leads to data inconsistency, as the overall operation is not atomic.
  **Line(s) to Fix:** 30-58
  **Current Code:**
  ```javascript
    const addResults = await Promise.all(
      pages.map(async (page) => {
        // ... (embedding and addVector calls)
        const vectorResult = await addVector({ /* ... */ });
        console.log("üß© Vector inserted with ID:", vectorResult.id);
        const chatId = uuidv4();
        runQuery( // This runs for each page
          `
    INSERT INTO files (userId, filePath, vectorId, chatId)
    VALUES (?, ?, ?, ?)
  `,
          [user.userId, req.file.path, vectorResult.id, chatId]
        );
        return vectorResult.id;
      })
    );
  ```
  **Suggested Fix:**
  Collect all data needed for the SQLite inserts *after* the `addVector` calls (which are naturally asynchronous). Then, perform a single batch insert or wrap the inserts in a database transaction for atomicity and performance. This also inherently addresses the missing `await` from the previous issue.

  ```javascript
  // 3Ô∏è‚É£ Process each page and collect data for batch insert
  const fileRecordsToInsert = [];
  const addResults = await Promise.all(
    pages.map(async (page) => {
      const embedding = await getEmbeddings(page.pageContent);
      const id = uuidv4(); // Vector ID
      const chatId = uuidv4(); // Chat ID for this file/page
      const vectorResult = await addVector({
        id,
        embedding,
        text: page.pageContent,
        metadata: { ...page.metadata, chatId }, // Add chatId to vector metadata if needed
      });

      logger.info("üß© Vector inserted with ID:", vectorResult.id);
      // Collect all necessary data for a single batch SQLite insert later
      fileRecordsToInsert.push([user.userId, req.file.path, vectorResult.id, chatId]);
      return vectorResult.id; // Return vector ID for the overall response
    })
  );

  // 4Ô∏è‚É£ Perform a single batch insert for file metadata using a SQLite transaction
  if (fileRecordsToInsert.length > 0) {
    await db.run('BEGIN TRANSACTION;'); // Start transaction
    try {
      const stmt = await db.prepare('INSERT INTO files (userId, filePath, vectorId, chatId) VALUES (?, ?, ?, ?)');
      for (const record of fileRecordsToInsert) {
        await stmt.run(record); // Insert each record within the transaction
      }
      await stmt.finalize(); // Finalize the prepared statement
      await db.run('COMMIT;'); // Commit the transaction
      logger.info(`‚úÖ Successfully inserted ${fileRecordsToInsert.length} file records into SQLite.`);
    } catch (dbError) {
      await db.run('ROLLBACK;'); // Rollback on error
      logger.error("‚ùå Error inserting file records into SQLite:", dbError);
      // Re-throw with a specific ApiError for consistency
      throw new ApiError(500, "Failed to record file metadata into database.", [dbError.message]);
    }
  }

  // 5Ô∏è‚É£ Response (now 4Ô∏è‚É£ in original steps count)
  logger.info(`Added ${addResults.length} page vectors successfully.`);
  return res.json({
    success: true,
    count: addResults.length,
    message: "PDF uploaded and processed successfully",
  });
  ```
  **Priority:** HIGH

**Line(s):** 65-67
- **Issue Type:** LOGIC / ERROR_HANDLING
  **Description:** The catch block re-throws a new `ApiError` with a generic 500 status. While this is generally good practice, if the original `error` is already an `ApiError` (e.g., thrown by `ApiError(404, "User not found")` if `runQuery` was properly `await`ed and caught), it's better to re-throw the original `ApiError` to preserve its specific status code and message. Otherwise, a specific client-facing error (like 404) could be masked as a generic 500.
  **Line(s) to Fix:** 65-67
  **Current Code:**
  ```javascript
  } catch (error) {
    logger.error("‚ùå Error in PDF upload handling:", error);
    throw new ApiError(500, "Failed to process PDF upload", [error.message]);
  }
  ```
  **Suggested Fix:**
  ```javascript
  } catch (error) {
    logger.error("‚ùå Error in PDF upload handling:", error);
    // If the error is already an ApiError, re-throw it to preserve its type and status
    if (error instanceof ApiError) {
      throw error;
    }
    // Otherwise, wrap generic errors in a 500 ApiError
    throw new ApiError(500, "Failed to process PDF upload", [error.message]);
  }
  ```
  **Priority:** MEDIUM

**Line(s):** 12-14, 49-53
- **Issue Type:** MAINTAINABILITY / DESIGN
  **Description:** SQL query strings are hardcoded directly within the controller logic. While the parameters are correctly parameterized (preventing direct SQL injection here), separating SQL queries into a dedicated data access layer (e.g., a repository or DAO) improves maintainability, readability, and testability. It makes the controller focus solely on request handling and business logic, delegating data persistence concerns.
  **Line(s) to Fix:** 12-14, 49-53
  **Current Code:**
  ```javascript
  const user = runQuery("SELECT userId FROM userData WHERE email = ? LIMIT 1", [ /* ... */ ]);
  // ...
  runQuery(
    `
    INSERT INTO files (userId, filePath, vectorId, chatId)
    VALUES (?, ?, ?, ?)
  `,
    [user.userId, req.file.path, vectorResult.id, chatId]
  );
  ```
  **Suggested Fix:**
  Create dedicated repository modules (e.g., `user.repository.js` and `file.repository.js`) to encapsulate database operations.

  `server/src/repositories/user.repository.js`:
  ```javascript
  import { runQuery } from "../database/sqlLite.db.js";

  export const getUserByEmail = async (email) => {
    return runQuery("SELECT userId FROM userData WHERE email = ? LIMIT 1", [email]);
  };
  ```

  `server/src/repositories/file.repository.js`:
  ```javascript
  import { db, runQuery } from "../database/sqlLite.db.js";

  export const insertFileRecord = async (userId, filePath, vectorId, chatId) => {
    return runQuery(
      `INSERT INTO files (userId, filePath, vectorId, chatId) VALUES (?, ?, ?, ?)`,
      [userId, filePath, vectorId, chatId]
    );
  };

  export const batchInsertFileRecords = async (records) => {
    await db.run('BEGIN TRANSACTION;');
    try {
      const stmt = await db.prepare('INSERT INTO files (userId, filePath, vectorId, chatId) VALUES (?, ?, ?, ?)');
      for (const record of records) {
        await stmt.run(record);
      }
      await stmt.finalize();
      await db.run('COMMIT;');
      return true; // Indicate success
    } catch (dbError) {
      await db.run('ROLLBACK;');
      throw dbError; // Re-throw to be handled by the controller's catch block
    }
  };
  ```

  Then, refactor `upload.controller.js` to use these repositories:
  ```javascript
  import { chunkPdf } from "../services/langchain.service.js";
  import { getEmbeddings } from "../services/llm.service.js";
  import { v4 as uuidv4 } from "uuid";
  import { addVector } from "../services/chromadb.service.js";
  import { logger } from "../utils/logger.js";
  import ApiError from "../utils/ApiError.js";
  // import { db, runQuery } from "../database/sqlLite.db.js"; // No longer needed directly for queries
  import { getUserByEmail } from "../repositories/user.repository.js";
  import { batchInsertFileRecords } from "../repositories/file.repository.js";


  export const handlePdfUpload = async (req, res) => {
    try {
      logger.info("Uploaded file:", req.file);

      // 1Ô∏è‚É£ Get userId from email using repository
      const user = await getUserByEmail(req.user.email);
      if (!user || !user.userId) {
        throw new ApiError(404, "User not found", [req.user.email]);
      }
      logger.info("User found:", user);

      // 2Ô∏è‚É£ Chunk the PDF into pages
      const pages = await chunkPdf(req.file.path);

      // 3Ô∏è‚É£ Process each page and collect data for batch insert
      const fileRecordsToInsert = [];
      const addResults = await Promise.all(
        pages.map(async (page) => {
          const embedding = await getEmbeddings(page.pageContent);
          const id = uuidv4(); // Vector ID
          const chatId = uuidv4(); // Chat ID for this file/page
          const vectorResult = await addVector({
            id,
            embedding,
            text: page.pageContent,
            metadata: { ...page.metadata, chatId }, // Add chatId to vector metadata if needed
          });

          logger.info("üß© Vector inserted with ID:", vectorResult.id);
          fileRecordsToInsert.push([user.userId, req.file.path, vectorResult.id, chatId]);
          return vectorResult.id;
        })
      );

      // 4Ô∏è‚É£ Perform a single batch insert for file metadata using repository
      if (fileRecordsToInsert.length > 0) {
        await batchInsertFileRecords(fileRecordsToInsert);
      }

      // 5Ô∏è‚É£ Response
      logger.info(`Added ${addResults.length} page vectors successfully.`);
      return res.json({
        success: true,
        count: addResults.length,
        message: "PDF uploaded and processed successfully",
      });
    } catch (error) {
      logger.error("‚ùå Error in PDF upload handling:", error);
      if (error instanceof ApiError) {
        throw error;
      }
      throw new ApiError(500, "Failed to process PDF upload", [error.message]);
    }
  };
  ```
  **Priority:** MEDIUM