**Overall Review Summary:**
- **Total Issues Found:** 7
- **Critical Issues:** 3 (Missing `await`, Untrapped Error, Data Inconsistency)
- **Code Quality Score:** 6/10
- **Approval Status:** NEEDS_CHANGES
- **Key Recommendations:**
    1.  Ensure all asynchronous operations (`runQuery`) are properly `await`ed and within a `try...catch` block.
    2.  Implement transactional integrity for database operations involving multiple steps to ensure data consistency.
    3.  Consolidate `INSERT` operations for better performance when dealing with multiple records.

---

### File-by-File Review

**File:** `server/src/controllers/upload.controller.js`

**Line(s):** 4, 8
- **Issue Type:** STYLE
  **Description:** The `uuidv4` import is duplicated. It's imported once on line 4 and again on line 8.
  **Line(s) to Fix:** 8
  **Current Code:**
  ```javascript
  import { v4 as uuidv4 } from "uuid";
  import { addVector } from "../services/chromadb.service.js";
  import { logger } from "../utils/logger.js";
  import ApiError from "../utils/ApiError.js";
  import { db, runQuery } from "../database/sqlLite.db.js";
  import { v4 as uuidv4 } from "uuid";
  ```
  **Suggested Fix:**
  ```javascript
  import { v4 as uuidv4 } from "uuid";
  import { addVector } from "../services/chromadb.service.js";
  import { logger } from "../utils/logger.js";
  import ApiError from "../utils/ApiError.js";
  import { db, runQuery } from "../database/sqlLite.db.js";
  // remove the duplicate import
  ```
  **Priority:** MINOR

**Line(s):** 11-14
- **Issue Type:** BUG / LOGIC / MAINTAINABILITY
  **Description:** The `runQuery` call to retrieve the user is missing an `await` keyword. `runQuery` likely returns a Promise, and without `await`, the `user` variable will hold a Promise object instead of the resolved user data. This will cause the `if (!user)` check to pass incorrectly (as a Promise is a truthy value), and subsequently `user.userId` to be accessed on a Promise object, leading to a runtime error or incorrect behavior. Additionally, this operation is outside the `try...catch` block, meaning if `runQuery` throws an error, it will not be caught.
  **Line(s) to Fix:** 11-14
  **Current Code:**
  ```javascript
  export const handlePdfUpload = async (req, res) => {
    //console.log("üìÇ Uploaded File:", req.file);\r\n
    const user = runQuery("SELECT userId FROM userData WHERE email = ? LIMIT 1", [\r\n
      req.user.email,\r\n
    ]);
    console.log("User found:", user);
    try {
      logger.info("Uploaded file:", req.file);
      // ...
    } catch (error) { /* ... */ }
  };
  ```
  **Suggested Fix:**
  ```javascript
  export const handlePdfUpload = async (req, res) => {
    // Wrap the initial DB call in the try...catch block
    try {
      logger.info("Uploaded file:", req.file);

      // 1Ô∏è‚É£ Get userId from email
      const user = await runQuery("SELECT userId FROM userData WHERE email = ? LIMIT 1", [
        req.user.email,
      ]);

      // Assuming runQuery for SELECT returns the row object directly or null/undefined
      // if no row found. If it returns an array, adjust the check: `if (!user || user.length === 0)`
      if (!user) {
        throw new ApiError(404, "User not found", [req.user.email]);
      }
      // ... rest of the code
    } catch (error) {
      logger.error("‚ùå Error in PDF upload handling:", error);
      // Ensure specific ApiErrors are re-thrown, otherwise catch as 500
      if (error instanceof ApiError) {
        throw error;
      }
      throw new ApiError(500, "Failed to process PDF upload", [error.message]);
    }
  };
  ```
  **Priority:** HIGH

**Line(s):** 15, 39
- **Issue Type:** STYLE
  **Description:** `console.log` statements are used for debugging or information logging. In a production environment, these should be replaced with the `logger` utility for consistent and configurable logging.
  **Line(s) to Fix:** 15, 39
  **Current Code:**
  ```javascript
  console.log("User found:", user);
  // ...
  console.log("üß© Vector inserted with ID:", vectorResult.id);
  ```
  **Suggested Fix:**
  ```javascript
  logger.info("User found:", user);
  // ...
  logger.info("üß© Vector inserted with ID:", vectorResult.id);
  ```
  **Priority:** MEDIUM

**Line(s):** 44-48
- **Issue Type:** BUG / PERFORMANCE / DATA_CONSISTENCY
  **Description:** The `runQuery` call for inserting file metadata into SQLite is missing an `await` keyword. This makes the database operation "fire and forget." The `Promise.all` will not wait for this operation to complete, which can lead to:
    1.  **Race Conditions/Inconsistency:** If the main process finishes and responds before the database writes are complete, subsequent reads might see an inconsistent state.
    2.  **Untrapped Errors:** Any error during this `runQuery` will not be caught by the surrounding `try...catch` block (or by the `Promise.all` error handling), leading to unhandled promise rejections and potential application crashes or silent failures.
    3.  **Performance:** While not a critical performance issue for a single insert, if `runQuery` is doing a lot of work synchronously or involves network calls, it can impact the overall throughput of `Promise.all` if not awaited.
  **Line(s) to Fix:** 44-48
  **Current Code:**
  ```javascript
  runQuery(
    `
    INSERT INTO files (userId, filePath, vectorId)
    VALUES (?, ?, ?)
  `,
    [user.userId, req.file.path, vectorResult.id]
  );
  ```
  **Suggested Fix:**
  ```javascript
  await runQuery( // <--- Add await here
    `
    INSERT INTO files (userId, filePath, vectorId)
    VALUES (?, ?, ?)
  `,
    [user.userId, req.file.path, vectorResult.id]
  );
  ```
  **Priority:** HIGH

**Line(s):** 30-50 (within `pages.map`)
- **Issue Type:** PERFORMANCE / DATA_CONSISTENCY / MAINTAINABILITY
  **Description:** The code performs an `addVector` operation to ChromaDB and then a separate `runQuery` for SQLite *for each page individually* inside the `Promise.all` loop.
    1.  **Performance:** Running `N` separate `INSERT` statements for `N` pages can be much slower than a single batch insert or a transaction if the database supports it. Each `runQuery` often involves overhead like opening/closing connections or transaction commits.
    2.  **Atomicity/Data Consistency:** If `addVector` succeeds for a page but the subsequent `runQuery` for SQLite fails (e.g., due to a unique constraint violation or database error), you will have orphaned vectors in ChromaDB without corresponding entries in your SQLite `files` table, leading to data inconsistency.
  **Line(s) to Fix:** 30-50
  **Current Code:**
  ```javascript
  pages.map(async (page) => {
    // Generate embedding
    const embedding = await getEmbeddings(page.pageContent);
    const id = uuidv4();
    const vectorResult = await addVector({
      id,
      embedding,
      text: page.pageContent,
      metadata: page.metadata,
    });
    // ...
    runQuery( // This runs for each page
      `
      INSERT INTO files (userId, filePath, vectorId)
      VALUES (?, ?, ?)
    `,
      [user.userId, req.file.path, vectorResult.id]
    );
    return vectorResult.id;
  })
  ```
  **Suggested Fix:**
  Consider collecting all `vectorId` and `filePath` pairs first, then performing a single batch insert after all vectors are added. For SQLite, this might involve constructing a multi-row insert statement or using a transaction.

  ```javascript
  // After Promise.all for addVector, collect the data for batch insert
  const fileRecords = [];
  const addResults = await Promise.all(
    pages.map(async (page) => {
      const embedding = await getEmbeddings(page.pageContent);
      const id = uuidv4();
      const vectorResult = await addVector({
        id,
        embedding,
        text: page.pageContent,
        metadata: page.metadata,
      });

      logger.info("üß© Vector inserted with ID:", vectorResult.id);
      fileRecords.push([user.userId, req.file.path, vectorResult.id]); // Collect for batch insert
      return vectorResult.id;
    })
  );

  // Perform a single batch insert or wrap in a transaction
  // (Assuming runQuery can handle multiple rows or you can structure a transaction)
  // Example for SQLite transaction:
  await db.run('BEGIN TRANSACTION;');
  try {
    const stmt = await db.prepare('INSERT INTO files (userId, filePath, vectorId) VALUES (?, ?, ?)');
    for (const record of fileRecords) {
      await stmt.run(record);
    }
    await stmt.finalize();
    await db.run('COMMIT;');
  } catch (dbError) {
    await db.run('ROLLBACK;');
    logger.error("‚ùå Error inserting file records into SQLite:", dbError);
    throw new ApiError(500, "Failed to record file metadata", [dbError.message]);
  }
  ```
  **Priority:** HIGH

**Line(s):** 56-57
- **Issue Type:** LOGIC / ERROR_HANDLING
  **Description:** The catch block re-throws a new `ApiError` with a generic 500 status. While this is generally good practice, if the original `error` is already an `ApiError` (e.g., thrown by `ApiError(404, "User not found")` if `runQuery` was properly `await`ed and caught), it's better to re-throw the original `ApiError` to preserve its specific status code and message. Otherwise, a 404 error could be masked as a 500.
  **Line(s) to Fix:** 56-57
  **Current Code:**
  ```javascript
  } catch (error) {
    logger.error("‚ùå Error in PDF upload handling:", error);
    throw new ApiError(500, "Failed to process PDF upload", [error.message]);
  }
  ```
  **Suggested Fix:**
  ```javascript
  } catch (error) {
    logger.error("‚ùå Error in PDF upload handling:", error);
    // If the error is already an ApiError, re-throw it to preserve its type and status
    if (error instanceof ApiError) {
      throw error;
    }
    // Otherwise, wrap generic errors in a 500 ApiError
    throw new ApiError(500, "Failed to process PDF upload", [error.message]);
  }
  ```
  **Priority:** MEDIUM

**Line(s):** 24, 46
- **Issue Type:** SECURITY / MAINTAINABILITY
  **Description:** SQL query strings are hardcoded directly within the controller logic. While the parameters are correctly parameterized, separating SQL queries into a dedicated data access layer (e.g., a repository or DAO) improves maintainability, readability, and can help prevent SQL injection if parameters were ever directly concatenated (though not the case here). It also makes it easier to manage and test database interactions independently.
  **Line(s) to Fix:** 24, 46
  **Current Code:**
  ```javascript
    const user = await runQuery("SELECT userId FROM userData WHERE email = ? LIMIT 1", [ /* ... */ ]);
    // ...
    await runQuery(
      `
      INSERT INTO files (userId, filePath, vectorId)
      VALUES (?, ?, ?)
    `,
      [user.userId, req.file.path, vectorResult.id]
    );
  ```
  **Suggested Fix:**
  Create a `file.repository.js` or `user.repository.js` to encapsulate database operations.

  `server/src/repositories/user.repository.js`:
  ```javascript
  import { runQuery } from "../database/sqlLite.db.js";

  export const getUserByEmail = async (email) => {
    return runQuery("SELECT userId FROM userData WHERE email = ? LIMIT 1", [email]);
  };
  ```

  `server/src/repositories/file.repository.js`:
  ```javascript
  import { db, runQuery } from "../database/sqlLite.db.js";

  export const insertFileRecord = async (userId, filePath, vectorId) => {
    return runQuery(
      `INSERT INTO files (userId, filePath, vectorId) VALUES (?, ?, ?)`,
      [userId, filePath, vectorId]
    );
  };

  export const batchInsertFileRecords = async (records) => {
    await db.run('BEGIN TRANSACTION;');
    try {
      const stmt = await db.prepare('INSERT INTO files (userId, filePath, vectorId) VALUES (?, ?, ?)');
      for (const record of records) {
        await stmt.run(record);
      }
      await stmt.finalize();
      await db.run('COMMIT;');
      return true; // Or return success indicator
    } catch (dbError) {
      await db.run('ROLLBACK;');
      throw dbError; // Re-throw to be handled by controller's catch
    }
  };
  ```

  Then in `upload.controller.js`:
  ```javascript
  import { getUserByEmail } from "../repositories/user.repository.js";
  import { batchInsertFileRecords } from "../repositories/file.repository.js";
  // ... (other imports)

  export const handlePdfUpload = async (req, res) => {
    try {
      // ...
      const user = await getUserByEmail(req.user.email);
      // ...
      const fileRecords = [];
      const addResults = await Promise.all(
        pages.map(async (page) => {
          // ...
          fileRecords.push([user.userId, req.file.path, vectorResult.id]);
          return vectorResult.id;
        })
      );

      // Perform batch insert
      if (fileRecords.length > 0) {
        await batchInsertFileRecords(fileRecords);
      }
      // ...
    } catch (error) { /* ... */ }
  };
  ```
  **Priority:** MEDIUM