```
**Overall Review Summary:**
- **Total Issues Found:** 6
- **Critical Issues:** 2 (Missing `await` for initial DB call, Data Inconsistency/Performance due to non-transactional batch operations and unawaited inserts)
- **Code Quality Score:** 5/10
- **Approval Status:** NEEDS_CHANGES
- **Key Recommendations:**
    1.  **Address Asynchronous Operations:** Ensure all asynchronous database operations (`runQuery`) are properly `await`ed and contained within `try...catch` blocks to prevent unhandled promise rejections and logical errors. The initial user lookup is a critical example.
    2.  **Ensure Data Consistency & Performance:** Implement transactional integrity for database writes involving multiple records (e.g., linking vector results to file metadata). The current individual, unawaited inserts within a loop lead to severe performance issues and potential data loss/inconsistency. Batch inserts within a transaction are crucial.
    3.  **Improve Modularity:** Refactor SQL queries out of controller logic into a dedicated data access layer (e.g., repositories) for better separation of concerns, maintainability, and testability. This will also make the batch insert solution cleaner.

---

### File-by-File Review

**File:** `server/src/controllers/upload.controller.js`

**Line(s):** 8
- **Issue Type:** STYLE
  **Description:** The `uuidv4` import is duplicated. It's imported once on line 3 and again on line 8, which is redundant.
  **Line(s) to Fix:** 8
  **Current Code:**
  ```javascript
  import { v4 as uuidv4 } from "uuid";
  import { addVector } from "../services/chromadb.service.js";
  import { logger } from "../utils/logger.js";
  import ApiError from "../utils/ApiError.js";
  import { db, runQuery } from "../database/sqlLite.db.js";
  import { v4 as uuidv4 } from "uuid"; // <--- Duplicated import
  ```
  **Suggested Fix:**
  ```javascript
  import { chunkPdf } from "../services/langchain.service.js";
  import { getEmbeddings } from "../services/llm.service.js";
  import { v4 as uuidv4 } from "uuid"; // Keep this one
  import { addVector } from "../services/chromadb.service.js";
  import { logger } from "../utils/logger.js";
  import ApiError from "../utils/ApiError.js";
  import { db, runQuery } from "../database/sqlLite.db.js";
  // Remove the duplicate import on line 8 entirely.
  ```
  **Priority:** MINOR

**Line(s):** 12-14, 15, 21
- **Issue Type:** BUG / LOGIC / ERROR_HANDLING
  **Description:** The `runQuery` call to retrieve the user (`const user = runQuery(...)`) is missing an `await` keyword. Since `runQuery` likely returns a Promise, `user` will hold a Promise object, not the resolved user data. This leads to several critical issues:
    1.  The `console.log` on line 15 will incorrectly log the Promise object itself, not the user data.
    2.  The `if (!user)` check on line 21 will always evaluate to `false` because a Promise object is truthy, allowing execution to continue with an unresolved Promise instead of actual user data.
    3.  Accessing `user.userId` later in the code will result in a runtime error because the `userId` property does not exist directly on a Promise.
    4.  This database operation is placed *before* the main `try...catch` block. Any error thrown by `runQuery` will be unhandled, potentially crashing the application.
  **Line(s) to Fix:** 12-14, 15, 21
  **Current Code:**
  ```javascript
  export const handlePdfUpload = async (req, res) => {
    //console.log("üìÇ Uploaded File:", req.file);
    const user = runQuery("SELECT userId FROM userData WHERE email = ? LIMIT 1", [
      req.user.email,
    ]);
    console.log("User found:", user); // This will log the Promise object
    try {
      logger.info("Uploaded file:", req.file);

      // 1Ô∏è‚É£ Get userId from email

      if (!user) { // <--- Flawed check due to missing await (Promise is truthy)
        throw new ApiError(404, "User not found", [req.user.email]);
      }
      // ... rest of the try block
    } catch (error) { /* ... */ }
  };
  ```
  **Suggested Fix:**
  ```javascript
  export const handlePdfUpload = async (req, res) => {
    // ‚ö†Ô∏è Move initial DB call inside the try...catch block to ensure error handling
    try {
      logger.info("Uploaded file:", req.file);

      // 1Ô∏è‚É£ Get userId from email - MUST be awaited
      const user = await runQuery("SELECT userId FROM userData WHERE email = ? LIMIT 1", [
        req.user.email,
      ]);

      // Assuming runQuery for SELECT returns the first row object directly or null/undefined
      // if no row found. If it returns an array of rows, adjust the check (e.g., `!user || user.length === 0`).
      // For a single row, check for the existence of the user object AND its expected property.
      if (!user || !user.userId) { // Added !user.userId for robustness
        throw new ApiError(404, "User not found", [req.user.email]);
      }
      logger.info("User found:", user); // Replaced console.log with logger.info

      // ... rest of the try block
    } catch (error) {
      // ... (existing error handling, see also the suggested fix for lines 65-67)
    }
  };
  ```
  **Priority:** HIGH

**Line(s):** 15, 44
- **Issue Type:** STYLE / MAINTAINABILITY
  **Description:** `console.log` statements are used for debugging or informational logging. In a production environment, these should be replaced with the `logger` utility (already imported on line 5) for consistent, configurable, and production-ready logging.
  **Line(s) to Fix:** 15, 44
  **Current Code:**
  ```javascript
  console.log("User found:", user);
  // ...
  console.log("üß© Vector inserted with ID:", vectorResult.id);
  ```
  **Suggested Fix:**
  ```javascript
  logger.info("User found:", user);
  // ...
  logger.info("üß© Vector inserted with ID:", vectorResult.id);
  ```
  **Priority:** MEDIUM

**Line(s):** 49-58 (within `pages.map` loop)
- **Issue Type:** PERFORMANCE / DATA_CONSISTENCY / BUG
  **Description:** Performing an individual `runQuery` for each page inside the `Promise.all` loop, without `await`ing it, leads to several critical issues:
    1.  **Unawaited Promises (BUG):** The `runQuery` calls for inserting file data are not `await`ed. This means they are "fire and forget," executing asynchronously in the background. The `handlePdfUpload` function will return a response to the client *before* these database operations are guaranteed to complete. This can lead to silent failures where data is not persisted, making the system unreliable.
    2.  **Performance Overhead (PERFORMANCE):** Running `N` separate `INSERT` statements for `N` pages is significantly slower than a single batch insert or a single database transaction, due to the overhead of establishing database connections/sessions and committing each individual transaction.
    3.  **Data Inconsistency (DATA_CONSISTENCY):** If `addVector` succeeds for a page in ChromaDB but the subsequent `runQuery` for SQLite fails (e.g., due to a database error, or network issue), you will have orphaned vectors in ChromaDB without corresponding entries in your SQLite `files` table. This violates data consistency, as the overall operation (PDF upload, vectorize, and record file metadata) is not atomic.
  **Line(s) to Fix:** 49-58
  **Current Code:**
  ```javascript
        const chatId = uuidv4();
        runQuery( // <--- Missing await and outside of transaction
          `
    INSERT INTO files (userId, filePath, vectorId, chatId)
    VALUES (?, ?, ?, ?)
  `,
          [user.userId, req.file.path, vectorResult.id, chatId]
        );
  ```
  **Suggested Fix:**
  Collect all data needed for the SQLite inserts *after* the `addVector` calls (which are naturally asynchronous). Then, perform a single batch insert or wrap the inserts in a database transaction for atomicity and significant performance improvement. This ensures that either all file records are inserted or none are, matching the "all or nothing" principle for the overall PDF processing. This also integrates well with the suggested design pattern change for data access.

  ```javascript
  // (Assuming previous fixes are applied and user is properly awaited)

  // 3Ô∏è‚É£ Process each page and collect data for batch insert
  const fileRecordsToInsert = [];
  const addResults = await Promise.all(
    pages.map(async (page) => {
      const embedding = await getEmbeddings(page.pageContent);
      const id = uuidv4(); // Vector ID
      const chatId = uuidv4(); // Chat ID for this file/page
      const vectorResult = await addVector({
        id,
        embedding,
        text: page.pageContent,
        metadata: { ...page.metadata, chatId }, // Add chatId to vector metadata if needed
      });

      logger.info("üß© Vector inserted with ID:", vectorResult.id);
      // Collect all necessary data for a single batch SQLite insert later
      fileRecordsToInsert.push([user.userId, req.file.path, vectorResult.id, chatId]);
      return vectorResult.id; // Return vector ID for the overall response
    })
  );

  // 4Ô∏è‚É£ Perform a single batch insert for file metadata using a SQLite transaction
  if (fileRecordsToInsert.length > 0) {
    // Ensure 'db' is correctly imported and available, e.g., from sqlLite.db.js
    // Assuming db.run and db.prepare methods are available for transactions directly.
    await db.run('BEGIN TRANSACTION;'); // Start transaction
    try {
      // Prepare statement once for efficiency
      const stmt = await db.prepare('INSERT INTO files (userId, filePath, vectorId, chatId) VALUES (?, ?, ?, ?)');
      for (const record of fileRecordsToInsert) {
        await stmt.run(record); // Insert each record within the transaction
      }
      await stmt.finalize(); // Finalize the prepared statement
      await db.run('COMMIT;'); // Commit the transaction
      logger.info(`‚úÖ Successfully inserted ${fileRecordsToInsert.length} file records into SQLite.`);
    } catch (dbError) {
      await db.run('ROLLBACK;'); // Rollback on error
      logger.error("‚ùå Error inserting file records into SQLite (rolled back):", dbError);
      // Re-throw with a specific ApiError for consistency
      throw new ApiError(500, "Failed to record file metadata into database due to a transactional error.", [dbError.message]);
    }
  }
  // ... rest of the function (Response)
  ```
  **Priority:** HIGH

**Line(s):** 65-67
- **Issue Type:** LOGIC / ERROR_HANDLING
  **Description:** The catch block re-throws a new `ApiError` with a generic 500 status. While this is generally good practice for unexpected errors, if the original `error` is already an `ApiError` (e.g., thrown by `ApiError(404, "User not found")` from the refined user check), it's better to re-throw the original `ApiError` to preserve its specific status code and message. Otherwise, a specific client-facing error (like 404) could be masked as a generic 500.
  **Line(s) to Fix:** 65-67
  **Current Code:**
  ```javascript
  } catch (error) {
    logger.error("‚ùå Error in PDF upload handling:", error);
    throw new ApiError(500, "Failed to process PDF upload", [error.message]);
  }
  ```
  **Suggested Fix:**
  ```javascript
  } catch (error) {
    logger.error("‚ùå Error in PDF upload handling:", error);
    // If the error is already an ApiError, re-throw it to preserve its type and status
    if (error instanceof ApiError) {
      throw error;
    }
    // Otherwise, wrap generic errors in a 500 ApiError
    throw new ApiError(500, "Failed to process PDF upload", [error.message]);
  }
  ```
  **Priority:** MEDIUM

**Line(s):** 12-14, 50-58
- **Issue Type:** MAINTAINABILITY / DESIGN
  **Description:** SQL query strings are hardcoded directly within the controller logic. While the parameters are correctly parameterized (preventing direct SQL injection here), separating SQL queries into a dedicated data access layer (e.g., a repository or DAO) significantly improves maintainability, readability, and testability. It allows the controller to focus solely on request handling and business logic, delegating data persistence concerns to specialized modules. This also makes the batch insert solution (Priority: HIGH) cleaner and more manageable.
  **Line(s) to Fix:** 12-14, 50-58
  **Current Code:**
  ```javascript
  const user = runQuery("SELECT userId FROM userData WHERE email = ? LIMIT 1", [
    req.user.email,
  ]);
  // ...
        runQuery( // This was also unawaited, adding to the bug list
          `
    INSERT INTO files (userId, filePath, vectorId, chatId)
    VALUES (?, ?, ?, ?)
  `,
          [user.userId, req.file.path, vectorResult.id, chatId]
        );
  ```
  **Suggested Fix:**
  Create dedicated repository modules (e.g., `user.repository.js` and `file.repository.js`) to encapsulate database operations.

  `server/src/repositories/user.repository.js`:
  ```javascript
  import { runQuery } from "../database/sqlLite.db.js"; // Adjust path as necessary

  export const getUserByEmail = async (email) => {
    // `runQuery` is expected to return the first row directly or null/undefined
    const result = await runQuery("SELECT userId FROM userData WHERE email = ? LIMIT 1", [email]);
    return result;
  };
  ```

  `server/src/repositories/file.repository.js`:
  ```javascript
  import { db, runQuery } from "../database/sqlLite.db.js"; // Adjust path. Assuming 'db' is the direct connection for transactions.

  // If you ever need to insert a single record outside a batch:
  export const insertFileRecord = async (userId, filePath, vectorId, chatId) => {
    return await runQuery( // Ensure this is awaited too
      `INSERT INTO files (userId, filePath, vectorId, chatId) VALUES (?, ?, ?, ?)`,
      [userId, filePath, vectorId, chatId]
    );
  };

  export const batchInsertFileRecords = async (records) => {
    if (!db || typeof db.run !== 'function' || typeof db.prepare !== 'function') {
      throw new Error("Database connection object (db) is not properly initialized or does not support transactions.");
    }
    await db.run('BEGIN TRANSACTION;');
    try {
      const stmt = await db.prepare('INSERT INTO files (userId, filePath, vectorId, chatId) VALUES (?, ?, ?, ?)');
      for (const record of records) {
        await stmt.run(record);
      }
      await stmt.finalize();
      await db.run('COMMIT;');
      return true; // Indicate success
    } catch (dbError) {
      await db.run('ROLLBACK;');
      throw dbError; // Re-throw to be handled by the controller's catch block
    }
  };
  ```

  Then, refactor `upload.controller.js` to use these repositories:
  ```javascript
  import { chunkPdf } from "../services/langchain.service.js";
  import { getEmbeddings } from "../services/llm.service.js";
  import { v4 as uuidv4 } from "uuid";
  import { addVector } from "../services/chromadb.service.js";
  import { logger } from "../utils/logger.js";
  import ApiError from "../utils/ApiError.js";
  import { db } from "../database/sqlLite.db.js"; // Keep `db` if batchInsertFileRecords uses it directly
  import { getUserByEmail } from "../repositories/user.repository.js"; // New import
  import { batchInsertFileRecords } from "../repositories/file.repository.js"; // New import


  export const handlePdfUpload = async (req, res) => {
    try {
      logger.info("Uploaded file:", req.file);

      // 1Ô∏è‚É£ Get userId from email using repository
      const user = await getUserByEmail(req.user.email);
      if (!user || !user.userId) {
        throw new ApiError(404, "User not found", [req.user.email]);
      }
      logger.info("User found:", user);

      // 2Ô∏è‚É£ Chunk the PDF into pages
      const pages = await chunkPdf(req.file.path);

      // 3Ô∏è‚É£ Process each page and collect data for batch insert
      const fileRecordsToInsert = [];
      const addResults = await Promise.all(
        pages.map(async (page) => {
          const embedding = await getEmbeddings(page.pageContent);
          const id = uuidv4(); // Vector ID
          const chatId = uuidv4(); // Chat ID for this file/page
          const vectorResult = await addVector({
            id,
            embedding,
            text: page.pageContent,
            metadata: { ...page.metadata, chatId }, // Add chatId to vector metadata if needed
          });

          logger.info("üß© Vector inserted with ID:", vectorResult.id);
          fileRecordsToInsert.push([user.userId, req.file.path, vectorResult.id, chatId]);
          return vectorResult.id;
        })
      );

      // 4Ô∏è‚É£ Perform a single batch insert for file metadata using repository
      if (fileRecordsToInsert.length > 0) {
        await batchInsertFileRecords(fileRecordsToInsert);
      }

      // 5Ô∏è‚É£ Response
      logger.info(`Added ${addResults.length} page vectors successfully.`);
      return res.json({
        success: true,
        count: addResults.length,
        message: "PDF uploaded and processed successfully",
      });
    } catch (error) {
      logger.error("‚ùå Error in PDF upload handling:", error);
      if (error instanceof ApiError) {
        throw error;
      }
      throw new ApiError(500, "Failed to process PDF upload", [error.message]);
    }
  };
  ```
  **Priority:** MEDIUM
```