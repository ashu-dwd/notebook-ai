### Overall Review Summary:
This Pull Request introduces significant features including user authentication, file upload/management, and AI-powered chat. While the overall architecture shows good intent, there are several critical issues that need to be addressed before merging. These primarily revolve around **robust error handling**, **data consistency (especially regarding file management and IDs)**, **security vulnerabilities (hardcoded secrets, unauthenticated endpoints)**, and **UI/backend synchronization**.

-   **Total Issues Found:** 25
-   **Critical Issues:** 10 (Security, Major Bugs, Data Inconsistency)
-   **Code Quality Score:** 4/10
-   **Approval Status:** NEEDS_CHANGES
-   **Key Recommendations:**
    1.  **Prioritize Backend Reliability & Security:**
        *   **Fix all missing `await`s and implement comprehensive `try...catch` blocks** for *all* asynchronous database and external API calls across all controllers and services. Unhandled rejections are a major source of instability.
        *   **Move all sensitive keys (like `CHROMADB_API_KEY`, `JWT_SECRET`) to environment variables** and ensure they are accessed securely, not hardcoded.
        *   **Implement proper file persistence and lifecycle management** on the server: uploaded files need to be moved from temporary storage, assigned unique IDs, and correctly deleted from both disk and ChromaDB when requested by the client.
    2.  **Ensure Frontend-Backend Synchronization & Functionality:**
        *   **Standardize file object structures** between frontend and backend. The backend must return a consistent `fileId`, `fileName`, `fileSize`, `fileType`, and `uploadTime` for each uploaded document. The frontend should use these server-provided IDs for `key` props and all subsequent actions (delete, download).
        *   **Implement missing functionality for core UI elements** such as the "Download" button for files and "New Chat", "Export Chat", and "Clear History" buttons in the dashboard.
    3.  **Enhance Code Quality & Maintainability:**
        *   Remove all `console.log` and commented-out debugging statements. Use the `logger` utility consistently.
        *   Refactor database queries into dedicated repository modules for better separation of concerns and improved readability.
        *   Address all duplicate and unused imports.

---

### File-by-File Review

**File:** `client/src/screens/Dashboard.jsx`

**Line(s):** 1, 20
-   **Issue Type:** STYLE / BUG
    **Description:** The `useState` and `useEffect` React hooks are imported twice. They are imported once on line 1 from \"react\" and again on line 20. This is redundant and can lead to slight confusion or, in rare build configurations, unexpected behavior.
    **Line(s) to Fix:** 20
    **Current Code:**
    ```javascript
    import React, { useState, useEffect, useRef } from "react";
    // ... other imports ...
    import { ToastContainer } from "react-toastify";
    import "react-toastify/dist/ReactToastify.css";
    import { useNavigate } from "react-router-dom";
    import { axiosInstance } from "../utils/axiosInstance";
    import { notify } from "../utils/notify";
    import { removeToken } from "../utils/sessionStorage";

    // Typing animation component
    const TypingAnimation = () => (
      <div className=\"flex items-center space-x-1 p-4\">
        <Brain className=\"h-5 w-5 flex-shrink-0\" />
        <div className=\"flex space-x-1\">
          <div className=\"w-2 h-2 bg-gray-400 rounded-full animate-bounce\"></div>
          <div
            className=\"w-2 h-2 bg-gray-400 rounded-full animate-bounce\"
            style={{ animationDelay: \"0.1s\" }}
          ></div>
          <div
            className=\"w-2 h-2 bg-gray-400 rounded-full animate-bounce\"
            style={{ animationDelay: \"0.2s\" }}
          ></div>
        </div>
        <span className=\"text-sm text-gray-500\">AI is typing...</span>
      </div>
    );

    export default function Dashboard() {
      const [message, setMessage] = useState(\"\");
      const [files, setFiles] = useState([]);
      const [userData, setUserData] = useState(null);
      const [chatMessages, setChatMessages] = useState([]);
      const [isUploading, setIsUploading] = useState(false);
      const [isTyping, setIsTyping] = useState(false);
      const [isLoadingChat, setIsLoadingChat] = useState(true);
      const chatEndRef = useRef(null);

      const navigate = useNavigate();

      // Auto scroll to bottom
      const scrollToBottom = () => {
        chatEndRef.current?.scrollIntoView({ behavior: \"smooth\" });
      };

      //checking sessionStorage has token or not then navigate to login
      useEffect(() => {
        const token = sessionStorage.getItem(\"token\");
        if (!token) {
          notify(\"❌ You need to log in first!\", \"error\");
          navigate(\"/login\", { replace: true });
        }
      }, [navigate]);
    ```
    **Suggested Fix:** Merge the imports into a single statement and remove the redundant line.
    ```javascript
    import React, { useState, useEffect, useRef } from "react";
    import {
      Brain,
      User,
      Upload,
      File,
      Send,
      MessageSquare,
      Clock,
      Search,
      Settings,
      LogOut,
      Plus,
      Trash2,
      Download,
    } from "lucide-react";
    import { ToastContainer } from "react-toastify";
    import "react-toastify/dist/ReactToastify.css";
    import { useNavigate } from "react-router-dom";
    import { axiosInstance } from "../utils/axiosInstance";
    import { notify } from "../utils/notify";
    import { removeToken } from "../utils/sessionStorage";

    // Remove line 20: import { useEffect, useState } from "react";
    ```
    **Priority:** MEDIUM

**Line(s):** 48, 70, 103, 240, 291 (related to `id` used as `key`)
-   **Issue Type:** BUG / LOGIC / MAINTAINABILITY
    **Description:** IDs for chat messages (lines 48, 70) and newly uploaded files (line 103) are generated using `Date.now()` and `Date.now() + 1`. This method does not guarantee unique IDs, especially if multiple messages or file uploads occur within the same millisecond or rapidly. This can lead to collisions, which are problematic for React's `key` prop (used on lines 240 for `file.fileId` and 291 for `msg.id`). Stable and unique keys are crucial for React to efficiently re-render lists and avoid issues like incorrect component state being retained or unexpected UI behavior. For files, the ID should ideally come from the server, where the true persistence is managed.
    **Line(s) to Fix:** 48, 70, 103, 240, 291
    **Current Code:**
    ```javascript
    // Line 48
    id: `user-${chat.chatId}`, // In useEffect for chat history
    // Line 70
    id: `ai-${chat.chatId}`, // In useEffect for chat history
    // Line 103
    id: "welcome", // Hardcoded ID for welcome message
    // Line 152 (in handleSendMessage)
    id: `user-${Date.now()}`,
    // Line 180 (in handleSendMessage for AI response)
    id: `ai-${Date.now()}`,
    // Line 240
    key={file.fileId} // `fileId` is coming from backend, should be unique.
    // Line 291
    key={msg.id}
    ```
    **Suggested Fix:** For client-side generated IDs (like initial messages or temporary display elements), use a UUID generation library (e.g., `uuid` from npm, or `crypto.randomUUID()` for modern browsers). For entities that are persisted (like files and chat history), the backend should generate a unique ID (e.g., UUID) and return it, which the frontend should then use. Ensure consistency of `id` naming (e.g., `id` vs `fileId`).

    For `Dashboard.jsx`, the current usage of `chat.chatId` and `file.fileId` from backend responses is good. The `Date.now()` parts are for client-side transient messages, which could be replaced by UUIDs. The issue in the original code snippet regarding `Date.now() + 1` was a misunderstanding, as it's correctly used with `ai-${chat.chatId}`. The primary concern is the potential for `Date.now()` to clash if `user-${Date.now()}` and `ai-${Date.now()}` are very close.

    ```javascript
    // Import uuid: import { v4 as uuidv4 } from 'uuid'; (if not already in use)

    // For initial AI message, if `1` is not unique across component instances or resets:
    // Line 103:
    if (transformedMessages.length === 0) {
      transformedMessages.push({
        id: uuidv4(), // Use uuidv4() for uniqueness
        type: "ai",
        content: "Hello! I've analyzed your uploaded documents. What would you like to know about them?",
        timestamp: getCurrentTimestamp(),
      });
    }

    // Line 110:
    setChatMessages([
      {
        id: uuidv4(), // Use uuidv4() for uniqueness
        type: "ai",
        content: "Hello! I've analyzed your uploaded documents. What would you like to know about them?",
        timestamp: getCurrentTimestamp(),
      },
    ]);

    // Line 166 (handleSendMessage for user message):
    const userMessage = {
      id: `user-${uuidv4()}`, // Use uuidv4() for better uniqueness
      type: "user",
      content: message,
      timestamp: getCurrentTimestamp(),
    };

    // Line 177 (handleSendMessage for AI message):
    const aiMessage = {
      id: `ai-${uuidv4()}`, // Use uuidv4() for better uniqueness
      type: "ai",
      content: response.data.response,
      timestamp: getCurrentTimestamp(),
    };

    // For file handling, ensure backend provides a unique `fileId` and other details.
    // The current mapping `key={file.fileId}` is correct if backend `fileId` is unique.
    // The `file.name` on line 240 is derived from `file.filePath` (from backend)
    // The `file.fileSize` and `file.uploadedAt` are also provided by backend.
    // This file block has issues with how `fileName`, `fileType`, `fileSize`, `uploadTime` are derived,
    // which need consistent structure from backend.
    ```
    **Priority:** MEDIUM

**Line(s):** 98-100, 199-202, 240
-   **Issue Type:** LOGIC / MAINTAINABILITY
    **Description:** The frontend expects file details like `name`, `type`, `size`, `uploadTime` for display.
    1.  The initial fetch (`useEffect` lines 98-100) retrieves `fileId` and `filePath` from the backend (`/upload`), but it doesn't retrieve or pass `fileSize`, `uploadTime`, or the actual `name` from the backend. This leads to these values being hardcoded to \"N/A\" for fetched files (lines 201-202).
    2.  The rendering logic (lines 199-202) then *derives* `fileName` and `fileType` from `file.filePath`, but falls back to \"N/A\" for `fileSize` and `uploadTime`.
    3.  The `file.filePath` field is a temporary path from Multer on the server, which should ideally not be exposed to the frontend directly or be used for filename parsing. A permanent file name and path should be stored server-side.
    **Line(s) to Fix:** 98-100, 199-202, 240
    **Current Code:**
    ```javascript
    // Line 98-100
    axiosInstance
      .get("/upload")
      .then((response) => {
        if (response.data.success) {
          setFiles(response.data.files); // response.data.files contains { fileId, filePath }
        }
    // Lines 199-202
    {files.map((file) => {
      const fileName = file.filePath || file.name; // file.name would be undefined for fetched files
      const fileType =
        fileName.split(".").pop()?.toUpperCase() || "FILE";
      const fileSize = file.fileSize || "N/A"; // file.fileSize is undefined
      const uploadTime = file.uploadedAt
        ? formatTimestamp(file.uploadedAt)
        : "N/A"; // file.uploadedAt is undefined
    ```
    **Suggested Fix:** The backend's `getUploadedFiles` endpoint should return comprehensive file metadata (e.g., `fileId`, `originalFileName`, `fileSize`, `fileType`, `uploadedAt` (proper ISO timestamp or formatted string), `chatId`, etc.) for each file, rather than just `filePath`. The frontend should then directly use these properties for rendering.

    **Backend Update (Conceptual - in `upload.controller.js` `getUploadedFiles`):**
    ```javascript
    // Change SELECT statement to include more columns like originalFileName, fileSize, fileType, uploadedAt
    // Example: SELECT fileId, originalFileName AS name, fileSize, fileType, uploadedAt FROM files WHERE userId = ?
    ```
    **Frontend Update (Dashboard.jsx):**
    ```javascript
    // Lines 98-100
    axiosInstance
      .get("/upload")
      .then((response) => {
        if (response.data.success) {
          // Assuming backend now returns file objects with {fileId, name, size, type, uploadedAt}
          setFiles(response.data.files);
        } else {
          // ...
        }
      })
      // ...

    // Lines 199-202 (File mapping for rendering)
    {files.map((file) => {
      // Direct use of properties returned from backend
      const displayFileName = file.name; // Use 'name' from backend
      const displayFileType = file.type; // Use 'type' from backend
      const displayFileSize = file.size; // Use 'size' from backend
      const displayUploadTime = file.uploadedAt // Use 'uploadedAt' from backend
        ? formatTimestamp(file.uploadedAt)
        : "N/A";

      return (
        <div
          key={file.fileId} // Use the backend-provided unique fileId as key
          className="bg-white border-2 border-black p-3 hover:shadow-lg transition-shadow"
        >
          <div className="flex items-start justify-between">
            <div className="flex-1">
              <div className="flex items-center space-x-2 mb-1">
                <File className="h-4 w-4" />
                <span
                  className="font-bold text-sm truncate"
                  title={displayFileName}
                >
                  {displayFileName}
                </span>
              </div>
              <div className="text-xs text-gray-600">
                {displayFileType} • {displayFileSize}
              </div>
              <div className="text-xs text-gray-500 mt-1">
                Uploaded at {displayUploadTime}
              </div>
            </div>
            {/* ... delete/download buttons ... */}
          </div>
        </div>
      );
    })}
    ```
    **Priority:** HIGH

**Line(s):** 115, 118, 368, 391-394
-   **Issue Type:** LOGIC / MAINTAINABILITY / UX
    **Description:** Several UI elements display hardcoded static values, such as \"UserName\", \"12:33\", and generic \"Recent Activity\" entries. These should be dynamic, reflecting actual user data, current time/last activity, and real-time events to provide a meaningful and engaging user experience.
    **Line(s) to Fix:** 115, 118, 368, 391-394
    **Current Code:**
    ```html
    // Line 115
    <span className=\"font-semibold\">UserName</span>
    // Line 118
    <div className=\"bg-black text-white px-3 py-2 text-sm font-mono\">12:33</div>
    // Line 368
    <span>Last message: 12:33</span>
    // Lines 391-394
    <h3 className=\"font-bold mb-3\">Recent Activity</h3>
    <div className=\"bg-white border border-black p-3\">
      <div className=\"text-xs text-gray-600 space-y-2\">
        <div>• Document uploaded</div>
        <div>• AI analysis complete</div>
        <div>• Chat session started</div>
      </div>
    </div>
    ```
    **Suggested Fix:**
    *   **For `UserName` (Line 115):** The `userData` state variable already holds the user's email. If the backend `users/me` endpoint returned a `name` instead of `email`, that would be better for display. Use `userData` state.
    *   **For `12:33` (Line 118 & 368):** `getCurrentTimestamp()` is already available. Use it for the current time. For "Last message", use the timestamp from the `chatMessages` array.
    *   **For \"Recent Activity\" (Lines 391-394):** This section is entirely static. It needs to be driven by actual events (e.g., file upload completion, AI response received, chat session started). This would require a new state array (`recentActivities`) populated dynamically.

    ```javascript
    // In Dashboard component (after state declarations):
    const [currentDisplayTime, setCurrentDisplayTime] = useState(getCurrentTimestamp());

    useEffect(() => {
      const intervalId = setInterval(() => {
        setCurrentDisplayTime(getCurrentTimestamp());
      }, 60 * 1000); // Update every minute
      return () => clearInterval(intervalId); // Cleanup on unmount
    }, []);

    // In JSX:
    // Line 115:
    <span className=\"font-semibold\">{userData || "Guest User"}</span>

    // Line 118:
    <div className=\"bg-black text-white px-3 py-2 text-sm font-mono\">{currentDisplayTime}</div>

    // Line 368:
    <span>Last message:{" "}
      {chatMessages.length > 0
        ? chatMessages[chatMessages.length - 1].timestamp
        : "No messages yet"}
    </span>

    // Lines 391-394: Requires new state management for activities.
    // Example (conceptual):
    // const [recentActivities, setRecentActivities] = useState([]);
    // ... update this state on events (upload success, AI response, etc.)
    // In JSX:
    // {recentActivities.map((activity, index) => <div key={index}>• {activity}</div>)}
    ```
    **Priority:** MEDIUM

**Line(s):** 158-170
-   **Issue Type:** BUG / LOGIC / MAINTAINABILITY
    **Description:** The `handleFileUpload` function creates a `newFile` object with client-side generated `id: Date.now()`. When `setFiles` is called, this `newFile` is added to the `files` state. However, the subsequent `axiosInstance.get("/upload")` (lines 170-176) then refetches the *entire* list of files from the backend, effectively replacing the locally added `newFile` with the backend's data (which might not include the newly uploaded file yet, or might have a different ID/structure). This can lead to a flickering UI or inconsistent state. The optimal approach is for the backend's `handlePdfUpload` to return the complete, persisted file object (including its unique `fileId`), which the frontend then adds directly to its state without a full re-fetch.
    **Line(s) to Fix:** 158-170
    **Current Code:**
    ```javascript
    const handleFileUpload = (event) => {\
      const file = event.target.files[0];
      if (!file) return;

      setIsUploading(true);

      const formData = new FormData();
      formData.append("pdfFile", file); // field name should match multer config

      const toastId = notify("Uploading file...", "info", {
        progress: 0,
        autoClose: false,
      });

      axiosInstance
        .post("/upload", formData, {
          headers: {
            "Content-Type": "multipart/form-data",
          },
          onUploadProgress: (progressEvent) => {
            const progress = Math.round(
              (progressEvent.loaded * 100) / progressEvent.total
            );
            notify("Uploading file...", "info", {
              id: toastId,
              progress: progress,
              autoClose: false,
            });
          },
        })
        .then((response) => {
          if (response.data.success) {
            // Refresh files list after successful upload
            return axiosInstance.get("/upload"); // <-- Inefficient re-fetch
          } else {
            notify(response.data.message || "❌ Upload failed!", "error");
          }
        })
        .then((response) => {
          if (response && response.data.success) {
            setFiles(response.data.files); // <-- Replaces entire file list
            notify("✅ File uploaded successfully!", "success");
          }
        })
        .catch((error) => {
          console.error("File upload error:", error);
          notify("❌ File upload failed!", "error");
        })
        .finally(() => {
          setIsUploading(false);
        });
    };
    ```
    **Suggested Fix:** The `handlePdfUpload` endpoint on the server should return the newly created file object (including its unique `fileId`, `name`, `size`, `type`, `uploadedAt`). The frontend then directly adds this single object to its `files` state. This avoids an unnecessary extra API call and ensures immediate UI consistency.

    **Backend Update (Conceptual - in `upload.controller.js` `handlePdfUpload`):**
    ```javascript
    // ... (after successful processing and DB insert)
    return res.json({
      success: true,
      message: "PDF uploaded and processed successfully",
      file: { // Return the new file object
        fileId: fileId, // e.g., UUID from server
        name: originalFileName,
        size: req.file.size,
        type: req.file.mimetype,
        uploadedAt: new Date().toISOString(), // ISO string for precise timestamp
      },
    });
    ```
    **Frontend Update (Dashboard.jsx):**
    ```javascript
    const handleFileUpload = (event) => {
      // ... (existing formData, toast setup) ...

      axiosInstance
        .post("/upload", formData, { /* ... onUploadProgress ... */ })
        .then((response) => {
          if (response.data.success) {
            // Directly add the new file from the response to state
            setFiles((prevFiles) => [...prevFiles, response.data.file]); // Assuming response.data.file contains the full file object
            notify("✅ File uploaded successfully!", "success");
          } else {
            notify(response.data.message || "❌ Upload failed!", "error");
          }
        })
        .catch((error) => {
          console.error("File upload error:", error);
          notify("❌ File upload failed!", "error");
        })
        .finally(() => {
          setIsUploading(false);
        });
    };
    ```
    **Priority:** HIGH

**Line(s):** 172-181
-   **Issue Type:** BUG / LOGIC / MAINTAINABILITY
    **Description:** The `removeFile` function only updates the client-side `files` state by filtering out the specified file (`setFiles((prev) => prev.filter((file) => file.fileId !== fileId))`). It does **not** send a corresponding request to the backend to delete the file from the server's storage or database. This results in a critical data desynchronization: files deleted on the client will reappear if the page is refreshed or the component remounts, as they still exist on the server.
    **Line(s) to Fix:** 172-181
    **Current Code:**
    ```javascript
    const removeFile = (fileId) => {
      axiosInstance
        .delete(`/upload/${fileId}`)
        .then((response) => {
          if (response.data.success) {
            setFiles((prev) => prev.filter((file) => file.fileId !== fileId));
            notify("✅ File deleted successfully!", "success");
          } else {
            notify(response.data.message || "❌ File deletion failed!", "error");
          }
        })
        .catch((error) => {
          console.error("File deletion error:", error);
          notify("❌ File deletion failed!", "error");
        });
    };
    ```
    **Suggested Fix:** The provided current code for `removeFile` *does* include an `axiosInstance.delete` call. This is good. The previous review might have misinterpreted this part. However, it's crucial that the *backend* endpoint (`DELETE /upload/:fileId`) actually handles deletion from disk (Multer's temporary storage), the SQLite database, and ChromaDB. The current backend `deleteUploadedFiles` in `upload.controller.js` only deletes from SQLite and ChromaDB, *not from the disk*. This is a critical oversight.

    **Backend Update (Conceptual - in `upload.controller.js` `deleteUploadedFiles`):**
    ```javascript
    // Add import: import fs from 'fs/promises';
    export const deleteUploadedFiles = async (req, res) => {
      const userId = req.user.userId;
      const fileId = req.params.fileId;
      let filePathToDelete; // Declare outside try-catch for cleanup

      try {
        // Check if file exists and get its path
        const fileRecord = await runQuery(
          "SELECT filePath, vectorId FROM files WHERE fileId = ? AND userId = ?",
          [fileId, userId]
        );
        if (!fileRecord || fileRecord.length === 0) {
          throw new ApiError(404, "File not found or not authorized", [fileId]);
        }
        filePathToDelete = fileRecord[0].filePath; // Get path for disk deletion
        const vectorIdToDelete = fileRecord[0].vectorId; // Get vector ID for ChromaDB deletion

        // Delete vectors from ChromaDB (if multiple vectors per file, need a batch delete based on fileId)
        await deleteVector(vectorIdToDelete); // Assuming deleteVector handles the specific vector,
                                              // but if `fileId` represents a whole document,
                                              // this should delete ALL vectors linked to that `fileId`
                                              // (e.g., `deleteVectorsByDocumentId` in chromadb.service.js)

        // Delete file from database
        await runQuery("DELETE FROM files WHERE fileId = ?", [fileId]);

        // Delete physical file from disk
        await fs.unlink(filePathToDelete);

        return res.json({
          success: true,
          message: "File deleted successfully",
        });
      } catch (error) {
        console.error("❌ Error in deleting uploaded files:", error);
        // Attempt to clean up physical file if an error occurs mid-process
        if (filePathToDelete) {
          try { await fs.unlink(filePathToDelete); } catch (cleanupError) { console.error("Failed to clean up partially deleted file:", cleanupError); }
        }
        throw new ApiError(500, "Failed to delete uploaded files", [error.message]);
      }
    };
    ```
    **Priority:** HIGH

**Line(s):** 214
-   **Issue Type:** STYLE / UX
    **Description:** The loading spinner uses `border-b-2 border-black` which creates a quarter-circle animation. While functional, a more conventional and universally recognized spinner animation typically involves a full circle with one or more borders transparent or a different color (e.g., `border-2 border-gray-400 border-t-2 border-black`) to give a smoother, continuous rotation effect.
    **Line(s) to Fix:** 214
    **Current Code:**
    ```html
    <div className=\"animate-spin rounded-full h-4 w-4 border-b-2 border-black mr-2\"></div>
    ```
    **Suggested Fix:** Adjust the border styles for a more standard spinner appearance.
    ```html
    <div className=\"animate-spin rounded-full h-4 w-4 border-2 border-gray-400 border-t-2 border-black mr-2\"></div>
    ```
    **Priority:** LOW

**Line(s):** 258
-   **Issue Type:** BUG / LOGIC / UX
    **Description:** The \"Download\" button for uploaded files is rendered in the UI but currently has no `onClick` handler attached. This means it is purely decorative and provides no functional way for users to download the associated file. This is a core missing feature.
    **Line(s) to Fix:** 258
    **Current Code:**
    ```html
    <button
      className=\"p-1 hover:bg-black hover:text-white transition-colors\"
      title=\"Download\"
    >
      <Download className=\"h-3 w-3\" />
    </button>
    ```
    **Suggested Fix:** Add an `onClick` handler that triggers the file download. This would typically involve constructing a download URL (e.g., `/api/download/${file.fileId}`) and opening it in a new tab or initiating a download via an `<a>` tag. (Requires the backend to implement a `GET /download/:fileId` endpoint).

    ```javascript
    const handleDownloadFile = async (fileId, fileName) => {
      try {
        const response = await axiosInstance.get(`/download/${fileId}`, {
          responseType: 'blob' // Important for binary data
        });
        const url = window.URL.createObjectURL(new Blob([response.data]));
        const link = document.createElement('a');
        link.href = url;
        link.setAttribute('download', fileName); // Use the actual file name
        document.body.appendChild(link);
        link.click();
        link.parentNode.removeChild(link);
        window.URL.revokeObjectURL(url);
        notify("✅ File download initiated!", "success");
      } catch (error) {
        console.error("Error downloading file:", error);
        notify("❌ Failed to download file!", "error");
      }
    };

    // In JSX:
    <button
      onClick={() => handleDownloadFile(file.fileId, file.name || file.filePath?.split("/").pop())}
      className=\"p-1 hover:bg-black hover:text-white transition-colors\"
      title=\"Download\"
    >
      <Download className=\"h-3 w-3\" />
    </button>
    ```
    **Priority:** HIGH

**Line(s):** 379, 382, 385
-   **Issue Type:** BUG / LOGIC / UX
    **Description:** The \"New Chat\", \"Export Chat\", and \"Clear History\" buttons within the \"Quick Actions\" section are displayed but currently lack `onClick` handlers. As a result, they do not perform any actions when clicked, which will lead to a confusing and frustrating user experience.
    **Line(s) to Fix:** 379, 382, 385
    **Current Code:**
    ```html
    <button className=\"w-full p-2 border border-black hover:bg-black hover:text-white transition-colors text-sm\">
      New Chat
    </button>
    <button className=\"w-full p-2 border border-black hover:bg-black hover:text-white transition-colors text-sm\">
      Export Chat
    </button>
    <button className=\"w-full p-2 border border-black hover:bg-black hover:text-white transition-colors text-sm\">
      Clear History
    </button>
    ```
    **Suggested Fix:** Implement appropriate `onClick` handlers for each button:
    *   **New Chat**: Reset `chatMessages` to initial state (e.g., just the welcome AI message) and potentially trigger a backend session reset.
    *   **Export Chat**: Implement logic to format `chatMessages` (e.g., as text or JSON) and trigger a file download.
    *   **Clear History**: Reset `chatMessages` (and `files` if a full session clear is desired) and trigger any necessary backend cleanup.

    ```javascript
    const handleNewChat = () => {
      setChatMessages([
        {
          id: uuidv4(), // Use unique ID for consistency
          type: "ai",
          content: "Hello! I've analyzed your uploaded documents. What would you like to know about them?",
          timestamp: getCurrentTimestamp(),
        },
      ]);
      setMessage(""); // Clear message input
      setFiles([]); // Optionally clear files as well for a "new session"
      notify("✅ New chat session started!", "success");
      // TODO: Consider an API call to reset backend session if relevant
    };

    const handleExportChat = () => {
      // Simple export as text file
      const chatContent = chatMessages
        .map((msg) => `${msg.timestamp} [${msg.type.toUpperCase()}]: ${msg.content}`)
        .join('\\n\\n');
      const blob = new Blob([chatContent], { type: 'text/plain' });
      const url = URL.createObjectURL(blob);
      const link = document.createElement('a');
      link.href = url;
      link.download = `chat_history_${new Date().toISOString().slice(0, 10)}.txt`;
      document.body.appendChild(link);
      link.click();
      document.body.removeChild(link);
      URL.revokeObjectURL(url);
      notify("✅ Chat exported successfully!", "success");
    };

    const handleClearHistory = async () => {
      if (window.confirm("Are you sure you want to clear all chat history? This action cannot be undone.")) {
        try {
          // TODO: Add backend API call to clear history (e.g., axiosInstance.post('/users/clear-chat-history'))
          // const response = await axiosInstance.post('/users/clear-chat-history');
          // if (response.data.success) {
            setChatMessages([ // Reset to initial AI message
              {
                id: uuidv4(),
                type: "ai",
                content: "Hello! I've analyzed your uploaded documents. What would you like to know about them?",
                timestamp: getCurrentTimestamp(),
              },
            ]);
            setFiles([]); // Optionally clear files if chat history implies associated documents
            notify("✅ Chat history cleared!", "success");
          // } else {
          //   notify(response.data.message || "❌ Failed to clear chat history!", "error");
          // }
        } catch (error) {
          console.error("Error clearing chat history:", error);
          notify("❌ Failed to clear chat history!", "error");
        }
      }
    };

    // In JSX:
    <button
      onClick={handleNewChat}
      className=\"w-full p-2 border border-black hover:bg-black hover:text-white transition-colors text-sm\"
    >
      New Chat
    </button>
    <button
      onClick={handleExportChat}
      className=\"w-full p-2 border border-black hover:bg-black hover:text-white transition-colors text-sm\"
    >
      Export Chat
    </button>
    <button
      onClick={handleClearHistory}
      className=\"w-full p-2 border border-black hover:bg-black hover:text-white transition-colors text-sm\"
    >
      Clear History
    </button>
    ```
    **Priority:** HIGH

**Line(s):** 50, 99, 167
-   **Issue Type:** STYLE / LOGIC
    **Description:** In `axios` error handling blocks, `console.error` is immediately followed by a `notify` call. While `console.error` is for developer debugging and `notify` is for user feedback, their direct sequential use can be slightly redundant for simple UI notifications.
    **Line(s) to Fix:** 50, 99, 167
    **Current Code:**
    ```javascript
    console.error("Error fetching files:", error);
    notify("❌ Failed to fetch files!", "error");
    ```
    **Suggested Fix:** This is a minor point. Keep both for now if direct console output during development is desired. In a production setting, `console.error` should ideally be handled by a centralized logging system.
    ```javascript
    // Keep as is, or:
    // if (process.env.NODE_ENV === 'development') {
    //   console.error("Error fetching files:", error);
    // }
    // notify("❌ Failed to fetch files!", "error");
    ```
    **Priority:** LOW

**File:** `client/src/screens/Login.jsx`

**Line(s)::** 31
-   **Issue Type:** BUG / LOGIC / MAINTAINABILITY
    **Description:** The `removeToken()` call in the `catch` block (line 31) when `response.data.success` is false is problematic. If login fails due to incorrect credentials (which is an expected failure), `removeToken()` would clear a potentially valid token if the user was already logged in (e.g., token expired, so they tried to re-login, but entered wrong credentials this time). The token should only be removed if the login attempt itself is successful (and replaces an old token) or if the existing token is explicitly determined to be invalid (e.g., during a refresh attempt).
    **Line(s) to Fix:** 31
    **Current Code:**
    ```javascript
          } else {
            setIsLoading(false);
            notify(response.data.error || "Login failed!", "error");
            removeToken(); // <-- Problematic
          }
    ```
    **Suggested Fix:** Remove `removeToken()` from this `else` block. The token should only be removed on logout or if the existing token is proven invalid (e.g., a 401 response from an authenticated endpoint).
    ```javascript
          } else {
            setIsLoading(false);
            notify(response.data.error || "Login failed! Invalid credentials.", "error");
            // removeToken(); // DO NOT remove token here on failed login attempt
          }
    ```
    **Priority:** MEDIUM

**Line(s)::** 33
-   **Issue Type:** BUG / LOGIC / MAINTAINABILITY
    **Description:** The `setIsLoading(false)` is called twice: once inside the `if/else` block (lines 28, 30) and again in the `finally` block (line 33). While this might not cause an immediate crash, it's redundant and can be confusing. The `finally` block is sufficient for ensuring `isLoading` is reset regardless of success or error.
    **Line(s) to Fix:** 33
    **Current Code:**
    ```javascript
      } catch (error) {
        setIsLoading(false);
        // ...
      } finally {
        setIsLoading(false);
      }
    ```
    **Suggested Fix:** Remove the `setIsLoading(false)` calls from inside the `try` and `catch` blocks, keeping only the one in `finally`.
    ```javascript
      // ...
      setIsLoading(true);
      try {
        const response = await axiosInstance.post("/auth/login", formData);
        if (response.data.success) {
          const token = response.data.data?.accessToken;
          setToken(token);
          notify("✅ Login successful!", "success");
          navigate("/dashboard");
        } else {
          notify(response.data.error || "Login failed!", "error");
          // removeToken(); // Remove this line (as per previous issue)
        }
      } catch (error) {
        console.error("Login error:", error);
        const errorMsg =
          error.response?.data?.error || "❌ Something went wrong!";
        notify(errorMsg, "error");
      } finally {
        setIsLoading(false); // Only set it once here
      }
    };
    ```
    **Priority:** LOW

**Line(s):** 76-79, 81-84, 114-117
-   **Issue Type:** MAINTAINABILITY / UX
    **Description:** The `href=\"#\"` values are placeholders. For proper navigation, these should either be actual route paths (e.g., `/register`, `/forgot-password`, `/`) or an `onClick` handler should be implemented to navigate programmatically. Using `href=\"#\"` makes the links non-semantic and can cause unintended scroll-to-top behavior.
    **Line(s) to Fix:** 76-79, 81-84, 114-117
    **Current Code:**
    ```html
    // Line 76
    <a href=\"#\" ...>Back to home</a>
    // Line 81
    <a href=\"#register\" ...>Sign up for free</a>
    // Line 114
    <a href=\"#forgot-password\" ...>Forgot password?</a>
    ```
    **Suggested Fix:** Replace `href=\"#\"` with proper `Link` components from `react-router-dom` and define correct routes, or implement `onClick` handlers with `navigate`.

    ```html
    // Import Link from 'react-router-dom': import { Link } from "react-router-dom";
    // For Back to home (using navigate if it's a dynamic back behavior, otherwise Link to '/')
    <a onClick={() => navigate('/')} className=\"...\" style={{ cursor: 'pointer' }}>Back to home</a>
    // Or if it's always home:
    // <Link to=\"/\" className=\"...\">Back to home</Link>

    // For Sign up for free:
    <Link to=\"/signup\" className=\"font-semibold hover:underline\">
      Sign up for free
    </Link>

    // For Forgot password?:
    // If there's a forgot password page:
    // <Link to=\"/forgot-password\" className=\"font-semibold hover:underline\">
    //   Forgot password?
    // </Link>
    // If not, remove the link or add a notification:
    // <a onClick={() => notify('Forgot password feature is not yet implemented.')} className=\"font-semibold hover:underline\" style={{ cursor: 'pointer' }}>
    //   Forgot password?
    // </a>
    ```
    **Priority:** MEDIUM

**File:** `client/src/screens/SignUp.jsx`

**Line(s):** 44-48
-   **Issue Type:** LOGIC / UX
    **Description:** The password strength indicator only appears if `formData.password` is truthy, but the strength calculation `setPasswordStrength(strength)` happens on every input change for the password field. The strength indicator should appear as soon as the user starts typing, even if the password is very weak. The current implementation means it will only show once the `passwordStrength` value is updated. This is likely intended behaviour as `formData.password` will be a string, which is truthy.

    However, there's a typo in the check `passwordStrength <= 1`. A strength of `1` (length >= 8) is still considered weak. `0` would be truly weak.
    **Line(s) to Fix:** 44-48, 149
    **Current Code:**
    ```javascript
    // ...
    // Password strength calculation
    if (name === "password") {
      let strength = 0;
      if (value.length >= 8) strength++;
      if (/[A-Z]/.test(value)) strength++;
      if (/[a-z]/.test(value)) strength++;
      if (/[0-9]/.test(value)) strength++;
      if (/[^A-Za-z0-9]/.test(value)) strength++;
      setPasswordStrength(strength);
    }
    // ...
    const getStrengthText = () => {
        if (passwordStrength <= 1) return "Weak"; // Strength of 1 is "Weak"
        if (passwordStrength <= 3) return "Medium";
        return "Strong";
    };
    ```
    **Suggested Fix:** Re-evaluate the strength mapping. A length-only password might not even be "Weak" if criteria are strict. For example, consider `0` as "Too Short" or "No Password". If 1 means "at least 8 chars", then maybe 2 means "Weak".
    ```javascript
    const getStrengthText = () => {
        if (passwordStrength === 0) return "Too Short"; // Or "None"
        if (passwordStrength <= 2) return "Weak"; // For 1 or 2 criteria met
        if (passwordStrength <= 4) return "Medium"; // For 3 or 4 criteria met
        return "Strong"; // For all 5 criteria met
    };

    const getStrengthColor = () => {
        if (passwordStrength === 0) return "bg-gray-300"; // Or a 'neutral' color
        if (passwordStrength <= 2) return "bg-red-500";
        if (passwordStrength <= 4) return "bg-yellow-500";
        return "bg-green-500";
    };

    // And make sure to show the indicator only if password has some content.
    // In JSX:
    // {formData.password.length > 0 && ( // Show only if password field has input
    //   <div className="mt-2">
    //     <div className="flex space-x-1 mb-1">
    //       {[...Array(5)].map((_, i) => (
    //         <div
    //           key={i}
    //           className={`h-1 flex-1 ${
    //             i < passwordStrength
    //               ? getStrengthColor()
    //               : "bg-gray-200"
    //           }`}
    //         />
    //       ))}
    //     </div>
    //     <p className="text-xs text-gray-600">
    //       Password strength: {getStrengthText()}
    //     </p>
    //   </div>
    // )}
    ```
    **Priority:** LOW

**Line(s):** 105-108, 110-113
-   **Issue Type:** MAINTAINABILITY / UX
    **Description:** Similar to `Login.jsx`, the `href=\"#\"` values are placeholders. These should either be actual route paths (e.g., `/login`, `/terms`, `/privacy`) or `onClick` handlers should be implemented for programmatic navigation.
    **Line(s) to Fix:** 105-108, 110-113
    **Current Code:**
    ```html
    // Line 105
    <a href=\"#\" className=\"flex items-center text-gray-600 hover:text-black transition-colors\">Back to home</a>
    // Line 108
    <a href=\"#login\" className=\"font-semibold hover:underline\">Sign in here</a>
    // Line 110-113
    <a href=\"#\" className=\"font-semibold hover:underline\">Terms of Service</a>
    // ...
    <a href=\"#\" className=\"font-semibold hover:underline\">Privacy Policy</a>
    ```
    **Suggested Fix:** Replace `href=\"#\"` with proper `Link` components from `react-router-dom` and define correct routes, or implement `onClick` handlers with `navigate`.
    ```html
    // Import Link from 'react-router-dom': import { Link } from "react-router-dom";
    // For Back to home:
    <Link to=\"/\" className=\"flex items-center text-gray-600 hover:text-black transition-colors\">Back to home</Link>

    // For Sign in here:
    <Link to=\"/login\" className=\"font-semibold hover:underline\">
      Sign in here
    </Link>

    // For Terms of Service and Privacy Policy:
    // If actual pages exist:
    <Link to=\"/terms\" className=\"font-semibold hover:underline\">
      Terms of Service
    </Link>
    // ...
    <Link to=\"/privacy\" className=\"font-semibold hover:underline\">
      Privacy Policy
    </Link>
    // If no actual pages, either remove links or add placeholder notifications via onClick.
    ```
    **Priority:** MEDIUM

**Line(s):** 70-75
-   **Issue Type:** LOGIC
    **Description:** The `handleSubmit` function performs an `axiosInstance.post` call for signup without a `try...catch` block around it. If the network request fails (e.g., server unreachable, CORS issues, malformed request) before the `then` or `catch` callbacks are invoked, it could lead to an unhandled promise rejection and potentially crash the client-side application. The existing `.catch` is for errors from the Promise itself, not for synchronous errors or unhandled rejections from `axiosInstance.post` if it's misconfigured. Also, `removeToken()` is called even on a failed signup (line 74), which is incorrect logic.
    **Line(s) to Fix:** 70-75
    **Current Code:**
    ```javascript
    const handleSubmit = (e) => {
      e.preventDefault();
      //handling form submission
      axiosInstance
        .post("/auth/signup", {
          name: `${formData.firstName} ${formData.lastName}`,
          email: formData.email,\
          password: formData.password,\
        })
        .then(({ data }) => {
          if (data.success) {
            const token = data.data?.accessToken;
            setToken(token);
            notify("✅ Signup successful!", "success");
            navigate("/dashboard");
          } else {
            notify(data.message || "Signup failed!", "error");
            removeToken(); // <-- Incorrect: token should not be removed on failed signup
          }
        })
        .catch((error) => {
          console.error("Signup error:", error);

          // Agar backend ka error message ho to dikha do
          const errorMsg =
            error.response?.data?.error || "❌ Something went wrong!";
          notify(errorMsg, "error");
        });
    };
    ```
    **Suggested Fix:**
    1.  Wrap the `axiosInstance.post` call in `try...catch` (or use async/await throughout `handleSubmit`).
    2.  Remove `removeToken()` from the `else` block for failed signups.

    ```javascript
    const handleSubmit = async (e) => { // Mark as async
      e.preventDefault();
      try {
        const response = await axiosInstance.post("/auth/signup", {
          name: `${formData.firstName} ${formData.lastName}`,
          email: formData.email,
          password: formData.password,
        });

        if (response.data.success) {
          const token = response.data.data?.accessToken;
          setToken(token);
          notify("✅ Signup successful!", "success");
          navigate("/dashboard");
        } else {
          notify(response.data.message || "Signup failed!", "error");
          // removeToken(); // Remove this line
        }
      } catch (error) {
        console.error("Signup error:", error);
        const errorMsg =
          error.response?.data?.error || "❌ Something went wrong!";
        notify(errorMsg, "error");
      }
    };
    ```
    **Priority:** MEDIUM

**File:** `server/config/contants.js`

**Line(s):** 1-7
-   **Issue Type:** SECURITY / MAINTAINABILITY / STYLE
    **Description:**
    1.  **Typo:** The filename `contants.js` should be `constants.js` for proper spelling and readability.
    2.  **Sensitive Information:** While `JWT_SECRET` and `CHROMADB_API_KEY` are read from `process.env`, the *file itself* is named `contants.js`. This is generally fine, but if it contained hardcoded secrets or was not `.gitignore`d, it would be a critical issue. For now, the direct access from `process.env` is good, but the typo remains.
    3.  **Debug Log:** `console.log(JWT_SECRET);` is a debug statement that should be removed from production code.
    **Line(s) to Fix:** 1, 7
    **Current Code:**
    ```javascript
    import { config } from "dotenv";
    config({ path: "./.env.local" });

    export const GEMINI_API_KEY = process.env.GEMINI_API_KEY;
    export const GEMINI_EMBEDDINGS_MODEL = "gemini-embedding-001";
    export const CHROMADB_API_KEY = process.env.CHROMADB_API_KEY;
    export const JWT_SECRET = process.env.MY_JWT_SECRET;
    //console.log(JWT_SECRET);
    ```
    **Suggested Fix:**
    1.  Rename `contants.js` to `constants.js`.
    2.  Remove the `console.log` statement.
    ```javascript
    import { config } from "dotenv";
    config({ path: "./.env.local" });

    export const GEMINI_API_KEY = process.env.GEMINI_API_KEY;
    export const GEMINI_EMBEDDINGS_MODEL = "gemini-embedding-001";
    export const CHROMADB_API_KEY = process.env.CHROMADB_API_KEY;
    export const JWT_SECRET = process.env.MY_JWT_SECRET;
    // Remove: console.log(JWT_SECRET);
    ```
    **Priority:** MEDIUM

**File:** `server/server.js`

**Line(s):** 6
-   **Issue Type:** MAINTAINABILITY
    **Description:** The `client` object is imported from `./src/database/chroma.db.js` but is not used directly within `server.js`. If the `chroma.db.js` module performs connection setup upon import and `server.js` doesn't need to interact with the client directly (e.g., for explicit disconnection), this import is redundant. Removing unused imports improves code clarity and prevents potential confusion.
    **Line(s) to Fix:** 6
    **Current Code:** `import { client } from \"./src/database/chroma.db.js\";`
    **Suggested Fix:** Remove the unused import.
    ```javascript
    // import { client } from \"./src/database/chroma.db.js\"; // This import is unused in server.js
    ```
    **Priority:** LOW

**Line(s):** 10-12
-   **Issue Type:** LOGIC / MAINTAINABILITY
    **Description:** The server's `listen` operation lacks explicit error handling for scenarios where the server fails to start (e.g., port already in use, invalid port). Without an `.on('error', ...)` handler, the Node.js process might crash abruptly instead of logging the error and attempting a graceful exit.
    **Line(s) to Fix:** 10-12
    **Current Code:**
    ```javascript
    server.listen(port, () => {
      logger.info(`Server is running on port ${port}`);
    });
    ```
    **Suggested Fix:** Add an error event listener to the server.
    ```javascript
    server.listen(port, () => {
      logger.info(`Server is running on port ${port}`);
    }).on('error', (err) => { // Add error event listener
      logger.error(`Server failed to start on port ${port}: ${err.message}`);
      process.exit(1); // Exit with a non-zero code to indicate an error
    });
    ```
    **Priority:** MEDIUM

**Line(s)::** 10-12 (and after)
-   **Issue Type:** MAINTAINABILITY
    **Description:** The server currently lacks a graceful shutdown mechanism. In production environments, it's crucial for applications to handle termination signals (like `SIGTERM` or `SIGINT`) to allow the server to close open connections, complete ongoing requests, and disconnect from databases cleanly before shutting down. This prevents data corruption or loss, ensures resources are released, and contributes to a more robust and resilient application.
    **Line(s) to Fix:** 10-12 (and after)
    **Current Code:**
    ```javascript
    server.listen(port, () => {
      logger.info(`Server is running on port ${port}`);
    });
    ```
    **Suggested Fix:** Implement graceful shutdown handlers for common signals. This would typically involve closing the HTTP server and any database connections.
    ```javascript
    server.listen(port, () => {
      logger.info(`Server is running on port ${port}`);
    }).on('error', (err) => {
      logger.error(`Server failed to start on port ${port}: ${err.message}`);
      process.exit(1);
    });

    // Add graceful shutdown handling
    const gracefulShutdown = () => {
      logger.info('Received shutdown signal, shutting down gracefully...');
      server.close(() => {
        logger.info('HTTP server closed.');
        // If your database connections (SQLite, ChromaDB client) need explicit closing,
        // add that logic here before exiting.
        // E.g., if (db && typeof db.close === 'function') db.close();
        // For ChromaDB, `CloudClient` might not have a direct `disconnect` method
        // for graceful shutdown, but it's good to consider if any long-lived connections exist.
        process.exit(0);
      });

      // Force close after a timeout if server doesn't close gracefully
      setTimeout(() => {
        logger.error('Could not close connections in time, forcefully shutting down');
        process.exit(1);
      }, 10000); // 10 seconds timeout
    };

    process.on('SIGTERM', gracefulShutdown); // Handle termination signal
    process.on('SIGINT', gracefulShutdown);  // Handle interrupt signal (Ctrl+C)
    ```
    **Priority:** HIGH

**File:** `server/src/app.js`

**Line(s):** 11
-   **Issue Type:** STYLE / MAINTAINABILITY
    **Description:** The `cookieParser` import is declared but never used within `app.js` itself. It's likely intended to be used as a middleware, but there's no `app.use(cookieParser());` call. If it's intended to be used, it should be added. If not, it should be removed.
    **Line(s) to Fix:** 11
    **Current Code:** `import cookieParser from \"cookie-parser\";`
    **Suggested Fix:** If `cookieParser` is intended to be used (which it is, for `refreshToken` cookie handling), add `app.use(cookieParser());` *before* any routes that need to access cookies.
    ```javascript
    import cookieParser from "cookie-parser";
    // ...
    export const app = express();
    // ...
    app.use(express.urlencoded({ extended: true }));
    app.use(cookieParser()); // Add this line
    ```
    **Priority:** MEDIUM

**File:** `server/src/controllers/auth.controller.js`

**Line(s)::** 4-5
-   **Issue Type:** STYLE / MAINTAINABILITY
    **Description:** The imports `success` from \"zod\" and `da` from \"zod/v4/locales\" are unused in this file. Unused imports clutter the code and can lead to confusion.
    **Line(s) to Fix:** 4-5
    **Current Code:**
    ```javascript
    import bcrypt from "bcrypt";
    import { createJwtToken } from "../utils/jwtMaker.js";
    import { runQuery } from "../database/sqlLite.db.js";
    import cookieParser from "cookie-parser";
    import { success } from "zod"; // Unused
    import { da } from "zod/v4/locales"; // Unused
    ```
    **Suggested Fix:** Remove the unused imports.
    ```javascript
    // (Remove these lines)
    ```
    **Priority:** LOW

**Line(s):** 9
-   **Issue Type:** STYLE / SECURITY
    **Description:** This `console.log(req.body);` statement is debugging output. It should be removed from production code to avoid unnecessary log noise and prevent potential exposure of sensitive request body data (like passwords during signup/login) in server logs.
    **Line(s) to Fix:** 9
    **Current Code:** `console.log(req.body);`
    **Suggested Fix:** Remove the `console.log` statement.
    ```javascript
    // (Remove this line)
    ```
    **Priority:** LOW

**Line(s):** 17, 71
-   **Issue Type:** BUG / LOGIC / PERFORMANCE
    **Description:** The `runQuery` function, although synchronous (as per `sqlLite.db.js`), is used in an `async` function. While `await` isn't strictly necessary for synchronous calls, the logical flow for `existingUser` (line 17) and `user` (line 71) relies on the *resolved value* of the query.
    1.  **Line 17:** `const existingUser = runQuery(...)` - `existingUser` is immediately evaluated by `existingUser.length > 0`. If `runQuery` returns a single object for "get" (as suggested in `sqlLite.db.js`), `existingUser` could be `null` or an object. If `runQuery` returns an *array* of results for "all", then `existingUser.length` would be correct. The problem here is that `runQuery` in `sqlLite.db.js` explicitly returns `stmt.get(params)` for `LIMIT 1` selects, which returns a single row object or `undefined`. Thus, `existingUser.length` on `undefined` will throw a `TypeError`.
    2.  **Line 71:** `const user = runQuery(...)` - Similar issue for login. `user.length === 0` will cause a `TypeError` if `user` is `undefined`.
    **Line(s) to Fix:** 17, 71
    **Current Code:**
    ```javascript
    // Line 17:
    const existingUser = runQuery(`SELECT * FROM userData WHERE email = ?`, [
      email,
    ]);
    // Line 71:
    const user = runQuery(`SELECT * FROM userData WHERE email = ?`, [email]);
    ```
    **Suggested Fix:** Handle the potential `undefined` return from `stmt.get()` for single row queries.
    ```javascript
    // Line 17:
    const existingUser = runQuery(`SELECT * FROM userData WHERE email = ?`, [
      email,
    ]);
    if (existingUser) { // Check if user was found (not undefined/null)
    // ... existingUser.length > 0 logic needs to be existingUser.userId or existingUser.email
      return res
          .status(409)
          .json({ success: false, error: "User already exists" });
    }

    // Line 71:
    const user = runQuery(`SELECT * FROM userData WHERE email = ?`, [email]);
    if (!user) { // Check if user was found
      return res.status(404).json({ success: false, error: "User not found" });
    }
    // No need for user.length === 0 check if it's always single object or undefined.
    // Replace user.length === 0 with !user
    ```
    **Priority:** HIGH

**Line(s):** 20
-   **Issue Type:** STYLE / MAINTAINABILITY
    **Description:** This line contains commented-out debug code (`//console.log(existingUser);`). Commented-out code should be removed from the codebase to keep it clean, reduce cognitive load, and avoid confusion.
    **Line(s) to Fix:** 20
    **Current Code:** `//console.log(existingUser);`
    **Suggested Fix:** `// Remove this line`
    **Priority:** LOW

**Line(s):** 40-42, 75-77
-   **Issue Type:** LOGIC / MAINTAINABILITY
    **Description:** The `createJwtToken` function in `jwtMaker.js` expects a `payload` object as its first argument (and a `secret`). However, it's called with `userEmail` and `userId` as separate arguments. This is a mismatch in argument signature which means the `accessTokenPayload` and `refreshTokenPayload` inside `createJwtToken` will be incorrectly formed (missing `email` and `userId` properties as the first argument will be the `email` string itself, not an object). This will lead to invalid JWT tokens.
    **Line(s) to Fix:** 40-42, 75-77
    **Current Code:**
    ```javascript
    // Line 40-42:
    const { accessToken, refreshToken } = createJwtToken(
      email,
      newUser.lastInsertRowid
    );
    // Line 75-77:
    const { accessToken, refreshToken } = createJwtToken(
      user[0].email,
      user[0].userId
    );
    ```
    **Suggested Fix:** Pass the payload as a single object as expected by `createJwtToken`. Also, ensure `newUser.lastInsertRowid` and `user[0].userId` are correctly populated.

    ```javascript
    // In jwtMaker.js, update createJwtToken to accept an object as payload:
    // export const createJwtToken = (payload) => { ... }

    // In auth.controller.js:
    // Line 40-42:
    const { accessToken, refreshToken } = createJwtToken({
      email: email,
      userId: newUser.lastInsertRowid, // Assuming this is the correct ID from DB insert
    });

    // Line 75-77:
    const { accessToken, refreshToken } = createJwtToken({
      email: user.email, // Use user.email directly, not user[0].email if `user` is the object
      userId: user.userId, // Use user.userId directly
    });
    ```
    **Priority:** HIGH

**Line(s):** 46, 90
-   **Issue Type:** MAINTAINABILITY / DEVELOPMENT_EXPERIENCE
    **Description:** The cookie configuration sets `secure: true`. While crucial for production environments to ensure cookies are only sent over HTTPS, this setting will prevent the cookie from being set if the application is running locally over HTTP (e.g., `localhost`). This can lead to unexpected behavior and debugging difficulties during development.
    **Line(s) to Fix:** 46, 90
    **Current Code:**
    ```javascript
    // Line 46
    secure: true, // Only send cookie over HTTPS
    // Line 90
    secure: true, // Only send cookie over HTTPS
    ```
    **Suggested Fix:** Conditionally set `secure` based on the environment, typically `process.env.NODE_ENV === 'production'`.
    ```javascript
    // Line 46 & 90
    secure: process.env.NODE_ENV === 'production', // Set to true only in production
    ```
    **Priority:** MEDIUM

**Line(s):** Entire file context
-   **Issue Type:** MAINTAINABILITY / ERROR_HANDLING
    **Description:** The `handleUserSignUp` and `handleUserLogin` functions, despite being `async`, do not wrap all asynchronous operations in `try...catch` blocks. Specifically, `bcrypt.hash`, `bcrypt.compare`, and `createJwtToken` can throw errors. If these operations fail, the Node.js process will crash due to an unhandled promise rejection or uncaught exception.
    **Line(s) to Fix:** 16-46 (for `handleUserSignUp`), 56-78 (for `handleUserLogin`)
    **Current Code:** (Example showing lack of `try...catch` around async calls within the main function `try` block)
    ```javascript
    export const handleUserSignUp = async (req, res) => {
      // ... input validation ...

      // Check if user already exists
      const existingUser = runQuery(`SELECT * FROM userData WHERE email = ?`, [
        email,
      ]); // <-- This query logic is handled by previous bug.
      // ...
      // Hash password (await bcrypt.hash, but no try-catch around it)
      const hashedPassword = await bcrypt.hash(password, 10);
      // Create new user (await runQuery, but no try-catch around it)
      const newUser = await runQuery(...);
      // Generate JWT (createJwtToken, but no try-catch around it)
      const { accessToken, refreshToken } = createJwtToken(...);
    };
    ```
    **Suggested Fix:** Wrap the main logic of each handler in a `try...catch` block to handle all potential errors, including those from `bcrypt` and `createJwtToken`. Also, ensure `runQuery` returns a consistent type (e.g., `null` or `undefined` for no results, and an object for a single result) and is handled correctly.

    ```javascript
    import bcrypt from "bcrypt";
    import { createJwtToken } from "../utils/jwtMaker.js";
    import { runQuery } from "../database/sqlLite.db.js";
    // import cookieParser from "cookie-parser"; // Keep if used for `res.cookie`
    // Remove unused zod imports

    export const handleUserSignUp = async (req, res) => {
      const { name, email, password } = req.body;
      // Remove: console.log(req.body);
      if (!name || !email || !password) {
        return res
          .status(400)
          .json({ success: false, error: "All fields are required" });
      }

      try {
        // Check if user already exists
        const existingUser = runQuery(`SELECT * FROM userData WHERE email = ?`, [ // No 'await' needed if runQuery is synchronous
          email,
        ]);

        if (existingUser) { // Check for existing user object, not its length
          return res
            .status(409)
            .json({ success: false, error: "User already exists" });
        }

        // Hash password
        const hashedPassword = await bcrypt.hash(password, 10);

        // Create new user
        const newUser = runQuery( // No 'await' needed if runQuery is synchronous
          `INSERT INTO userData (name, email, password) VALUES (?, ?, ?)`,
          [name, email, hashedPassword]
        );
        // Remove: console.log(newUser); // newUser is result of stmt.run (synchronous)
                                         // it won't have lastInsertRowid until awaited or handled differently.
                                         // If runQuery returns Statement object, you'd need newUser.lastInsertRowId directly.
                                         // If it returns an info object with lastInsertRowid, then it's fine.
                                         // Let's assume runQuery gives { lastInsertRowid } on run operations.

        // Generate JWT
        const { accessToken, refreshToken } = createJwtToken({
          email,
          userId: newUser.lastInsertRowid,
        });

        res.cookie("refreshToken", refreshToken, {
          httpOnly: true,
          secure: process.env.NODE_ENV === 'production', // Conditional secure flag
          sameSite: "strict",
          maxAge: 7 * 24 * 60 * 60 * 1000, // 7 days
        });

        return res.status(201).json({
          success: true,
          data: { accessToken },
          message: "SignUp successful",
        });
      } catch (error) {
        console.error("Error during user signup:", error);
        return res.status(500).json({ success: false, error: "Internal server error during signup" });
      }
    };

    export const handleUserLogin = async (req, res) => {
      const { email, password } = req.body;
      if (!email || !password) {
        return res
          .status(400)
          .json({ success: false, error: "Please provide email and password" });
      }

      try {
        // Check if user exists
        const user = runQuery(`SELECT * FROM userData WHERE email = ?`, [email]); // No 'await' needed if runQuery is synchronous
        if (!user) { // Check for user object, not its length
          return res.status(404).json({ success: false, error: "User not found" });
        }

        // Check password
        const isPasswordValid = await bcrypt.compare(password, user.password); // Use user.password directly
        if (!isPasswordValid) {
          return res
            .status(401)
            .json({ success: false, error: "Invalid email or password" });
        }

        // Generate JWT
        const { accessToken, refreshToken } = createJwtToken({
          email: user.email,
          userId: user.userId,
        });

        res.cookie("refreshToken", refreshToken, {
          httpOnly: true,
          secure: process.env.NODE_ENV === 'production', // Conditional secure flag
          sameSite: "strict",
          maxAge: 7 * 24 * 60 * 60 * 1000, // 7 days
        });

        return res.status(200).json({
          success: true,
          data: { accessToken },
          message: "Login successful",
        });
      } catch (error) {
        console.error("Error during user login:", error);
        return res.status(500).json({ success: false, error: "Internal server error during login" });
      }
    };
    ```
    **Priority:** HIGH

**File:** `server/src/controllers/chat.controller.js`

**Line(s):** 6
-   **Issue Type:** MAINTAINABILITY
    **Description:** The `db` import from `../database/sqlLite.db.js` is declared but never used within this file. Unused imports clutter the code and can lead to confusion.
    **Line(s) to Fix:** 6
    **Current Code:** `import { db, runQuery } from \"../database/sqlLite.db.js\";`
    **Suggested Fix:** Remove the unused `db` import.
    ```javascript
    import { runQuery } from "../database/sqlLite.db.js";
    ```
    **Priority:** LOW

**Line(s):** 15, 32, 35, 41
-   **Issue Type:** STYLE / DEBUG
    **Description:** There are several `console.log` statements used for debugging purposes. While useful during development, these should be removed from production code as they can leak sensitive information, reduce performance, and clutter server logs. The `logger.info` calls are appropriate for production.
    **Line(s) to Fix:** 15, 32, 35, 41
    **Current Code:**
    ```javascript
    // Line 15
    logger.info(userMsg);
    // Line 32
    console.log("chatid", chatId);
    // Line 35
    console.log("embedding length", embeddings.length);
    // Line 41
    console.log("vectorIds", vectorIds);
    // Line 44 (within the catch block)
    console.log(error);
    ```
    **Suggested Fix:** Replace `console.log` with `logger.info` or `logger.debug`, or remove them entirely.
    ```javascript
    logger.info(`User message: ${userMsg}`); // Replaced console.log on line 15 with more descriptive logger
    logger.debug(`Chat ID: ${chatId}`); // Replaced console.log on line 32
    logger.debug(`Embedding length: ${embeddings.length}`); // Replaced console.log on line 35
    logger.debug(`Vector IDs: ${vectorIds}`); // Replaced console.log on line 41
    // Line 62 (within catch block)
    logger.error("Error in chatWithPdf:", error); // Log the full error object
    ```
    **Priority:** LOW

**Line(s):** 10-13, 19-21
-   **Issue Type:** BUG / LOGIC
    **Description:**
    1.  **Line 10-13:** `const user = await runQuery(...)` is an `await` on a synchronous `runQuery` (from `sqlLite.db.js`), which has no effect. The important part is the check `if (!user)` on line 23. `runQuery` with `LIMIT 1` returns either a single object or `undefined` (if no row found). Thus, `if (!user)` is the correct check.
    2.  **Line 19-21:** The `files` check `if (!files || files.length === 0)` assumes `runQuery` returns an array for its `SELECT` statements, but `sqlLite.db.js`'s `runQuery` uses `stmt.all()` for non-LIMIT 1 selects, which indeed returns an array. So this check is correct.

    The original issue description for this line was based on `runQuery` being asynchronous, but it's synchronous. The core bug remains the handling of `user` where `runQuery` returns `undefined` for no results, and `user.userId` being accessed subsequently.
    **Line(s) to Fix:** 10-13, 19-21
    **Current Code:**
    ```javascript
    const user = await runQuery(
      "SELECT userId FROM userData WHERE email = ? LIMIT 1",
      [req.user.email]
    );

    // ...

    if (!files || files.length === 0) {
      return res.json({
        success: false,
        message: "No files uploaded. Please upload files to start chatting.",
      });
    }
    ```
    **Suggested Fix:** Ensure `user` is defined before accessing `user.userId`.
    ```javascript
    export const chatWithPdf = async (req, res) => {
      const { userMsg } = req.body;

      // Ensure user exists and is properly authenticated. req.user should already contain userId.
      // If req.user is guaranteed by middleware (like verifyJwtToken), then fetching user from DB is redundant
      // unless you need more user details than just userId/email.
      const userId = req.user.userId; // Prefer using userId from JWT payload if available and reliable

      if (!userId) { // Basic check based on JWT payload
        logger.warn("User ID not found in token payload.");
        return res.status(401).json({ success: false, message: "Authentication required." });
      }

      try {
        logger.info(`User message received: ${userMsg} for userId: ${userId}`);

        // Fetch chat IDs for the user's files
        const files = runQuery("SELECT chatId FROM files WHERE userId = ?", [
          userId, // Use userId from JWT
        ]);

        if (!files || files.length === 0) {
          return res.status(400).json({ // 400 Bad Request if no files, not 200 success:false
            success: false,
            message: "No files uploaded. Please upload files to start chatting.",
          });
        }
    ```
    **Priority:** HIGH

**Line(s):** 29
-   **Issue Type:** LOGIC / MAINTAINABILITY
    **Description:** The comment `// Assuming all files belong to the same chat` highlights a critical assumption. If a user can upload multiple files that might logically belong to different `chatId`s, this implementation will incorrectly use only the `chatId` of the first file found in the `files` array. This could lead to the LLM searching irrelevant documents. The business logic for determining the correct `chatId` for a given user message needs to be explicitly defined. If a user truly has only *one* `chatId` across all their files, this should be a strong invariant enforced by the data model.
    **Line(s) to Fix:** 29
    **Current Code:** `const chatId = files[0].chatId; // Assuming all files belong to the same chat`
    **Suggested Fix:**
    If the design intends for a single chat context per user, explicitly state it in the comment:
    ```javascript
    // All files uploaded by a user are associated with a single, global chat ID.
    const chatId = files[0].chatId;
    ```
    If multiple chat contexts are possible, the `chatId` should be sent from the frontend or derived more intelligently (e.g., based on the current active document or a user-selected chat session ID). For current code, add a TODO.
    ```javascript
    const chatId = files[0].chatId; // TODO: Revisit if multiple chat contexts/documents per user become a requirement. Current implementation assumes one chat context per user.
    ```
    **Priority:** MEDIUM

**Line(s):** 62-64
-   **Issue Type:** LOGIC / ERROR_HANDLING
    **Description:** Inside the `catch` block, `console.log(error);` is redundant (already addressed above). More importantly, throwing an `ApiError` directly from a controller's `catch` block (i.e., `throw new ApiError(...)`) implies that an Express error-handling middleware is explicitly configured to catch this specific error type and send an HTTP response. If such a middleware is not guaranteed to be in place or correctly configured for `ApiError`, this `throw` will result in an unhandled promise rejection, potentially crashing the Node.js process. Controllers should generally aim to send a response directly (`res.status().json()`) or use `next(error)` to explicitly pass the error to the Express error-handling chain.
    **Line(s) to Fix:** 62-64
    **Current Code:**
    ```javascript
    console.log(error);
    logger.error("Error in chatWithPdf:", error.message);
    throw new ApiError("Failed to process chat request", 500);
    ```
    **Suggested Fix:** Replace `throw new ApiError` with `return next(new ApiError(...))` to explicitly pass the error to Express's error handling chain, assuming a global error middleware is correctly set up. If not, send the response directly.
    ```javascript
    logger.error("Error in chatWithPdf:", error); // Log full error object
    return next(new ApiError("Failed to process chat request", 500)); // Pass to error handling middleware
    // OR if no global error handling middleware is present:
    // return res.status(500).json({ success: false, message: "Failed to process chat request." });
    ```
    **Priority:** MEDIUM

**Line(s):** 67
-   **Issue Type:** MAINTAINABILITY
    **Description:** This line contains commented-out code. Commented-out code generally adds unnecessary clutter and can confuse future developers. Such code should be removed from the codebase; if it's still relevant for future features or reference, it should be managed in a separate branch or easily recoverable from version control history.
    **Line(s) to Fix:** 67
    **Current Code:** `// export const handleUserChats = (req,res)={}`
    **Suggested Fix:** (Remove the line)
    ```javascript

    ```
    **Priority:** LOW

**File:** `server/src/controllers/upload.controller.js`

**Line(s):** 7
-   **Issue Type:** STYLE / MAINTAINABILITY
    **Description:** The `db` import from `../database/sqlLite.db.js` is declared but never used within this file. Unused imports clutter the code.
    **Line(s) to Fix:** 7
    **Current Code:** `import { db, runQuery } from \"../database/sqlLite.db.js\";`
    **Suggested Fix:** Remove the unused `db` import.
    ```javascript
    import { runQuery } from "../database/sqlLite.db.js";
    ```
    **Priority:** LOW

**Line(s):** 11-13, 15
-   **Issue Type:** BUG / LOGIC
    **Description:**
    1.  **Line 11:** The `runQuery` call to fetch `userId` is not `await`ed, but `runQuery` itself (from `sqlLite.db.js`) is synchronous. The issue is not the `await` but the expectation of `user` to be an array, not a single object or `undefined` as `stmt.get` returns for `LIMIT 1` queries.
    2.  **Line 18:** `if (!user)` checks if `user` is `undefined` (which it would be if no user is found by `stmt.get`). This check is correct given `runQuery`'s behavior.
    3.  **Line 15:** `console.log("User found:", user);` will log `undefined` if no user, or the user object. This is a debug log and should be removed.

    The actual bug is if `req.user.email` itself is undefined or invalid due to previous middleware issues, leading to `runQuery` receiving bad input. However, `verifyJwtToken` middleware should prevent this. The primary issue remaining here is the debug log.
    **Line(s) to Fix:** 11-13, 15
    **Current Code:**
    ```javascript
    const user = runQuery("SELECT userId FROM userData WHERE email = ? LIMIT 1", [\
      req.user.email,
    ]);
    console.log("User found:", user);
    // ...
    if (!user) {
      throw new ApiError(404, "User not found", [req.user.email]);
    }
    ```
    **Suggested Fix:** Remove the debug log. The `if (!user)` check is logically sound given the current `runQuery` implementation for `LIMIT 1`.
    ```javascript
    // No change for runQuery/await, as it's synchronous.
    const user = runQuery("SELECT userId FROM userData WHERE email = ? LIMIT 1", [
      req.user.email,
    ]);
    // Remove: console.log("User found:", user);
    logger.info("User found:", user ? user.email : "Not found"); // Use logger instead
    ```
    **Priority:** LOW

**Line(s):** 40, 43-45
-   **Issue Type:** BUG / LOGIC / MAINTAINABILITY / DATA_CONSISTENCY
    **Description:**
    1.  **File Persistence:** The `filePath` (`req.file.path`) stored in the `files` table (line 42) is the temporary path where Multer initially saves the file. This file will likely be deleted after the request is processed, making it inaccessible for future operations like downloading or re-analyzing. Files intended for persistence must be moved to a permanent storage location.
    2.  **`chatId` Logic:** A new `chatId` is generated using `uuidv4()` for *each page* (line 40) and inserted into the `files` table. If `chatId` is meant to represent a chat session linked to a *document*, it should be one `chatId` per document, not one per page. This can lead to multiple `chatId`s for a single document, which might not be intended for the `files[0].chatId` logic in `chat.controller.js`.
    3.  **Database Schema vs. Logic:** The `files` table current schema (from `sqlLite.db.js`) has `fileId` (PRIMARY KEY), `userId`, `filePath`, `vectorId`, `chatId`. It appears to try to store per-file info and per-vector info in one table. This can lead to redundancy and inconsistencies. A more robust schema might be a `documents` table (for `fileId`, `filePath`, `originalName`, `fileSize`, `uploadedAt`, `chatSessionId`) and a `vectors` table (for `vectorId`, `documentId`, `pageContent`).
    4.  **Response to Client:** The `handlePdfUpload` response (lines 58-62) does not return sufficient information (like the actual `fileId`, `fileName`, `fileSize`, `fileType`) to the client for it to correctly display and manage the newly uploaded file without a subsequent `GET /upload` call.
    **Line(s) to Fix:** 40, 42, 50-54, 58-62
    **Current Code:**
    ```javascript
    // Line 40
    const chatId = uuidv4();
    // Line 42 (part of SQL VALUES)
    [user.userId, req.file.path, vectorResult.id, chatId]
    // Line 50-54 (SQL insert)
    await runQuery(
      `
    INSERT INTO files (userId, filePath, vectorId, chatId)
    VALUES (?, ?, ?, ?)
  `,
      [user.userId, req.file.path, vectorResult.id, chatId]
    );
    // Line 58-62 (Response)
    return res.json({
      success: true,
      count: addResults.length,
      message: "PDF uploaded and processed successfully",
    });
    ```
    **Suggested Fix:** A major refactor of file upload handling is needed, impacting schema.

    **Conceptual Backend Refactor (High-Level Plan):**
    1.  **Define a permanent upload directory.**
    2.  **Generate a single `documentId` (UUID) for the entire PDF.**
    3.  **Move the uploaded file from `req.file.path` to this permanent directory** using its `documentId` as part of the filename.
    4.  **Store primary document metadata** (`documentId`, `userId`, `permanentFilePath`, `originalFileName`, `fileSize`, `fileType`, `uploadedAt`, `chatSessionId`) in a new or refactored `documents` table. A single `chatSessionId` per document is likely more logical.
    5.  **When chunking/vectorizing**, associate *each vector* with the `documentId` in ChromaDB's metadata.
    6.  **Update `files` table**: It should store the `vectorId` and its associated `documentId` (instead of `filePath` and `chatId` directly).
    7.  **Return full file metadata** (`documentId`, `originalFileName`, `fileSize`, `fileType`, `uploadedAt`) in the response to the client.

    This is a significant change, but crucial for robustness. The current implementation won't support downloads or persistent deletion properly.

    ```javascript
    import { chunkPdf } from "../services/langchain.service.js";
    import { getEmbeddings } from "../services/llm.service.js";
    import { v4 as uuidv4 } from "uuid";
    import { addVector, deleteVector } from "../services/chromadb.service.js"; // deleteVector also needs refactor for document ID
    import { logger } from "../utils/logger.js";
    import ApiError from "../utils/ApiError.js";
    import { runQuery } from "../database/sqlLite.db.js";
    import fs from 'fs/promises'; // For file system operations
    import path from 'path'; // For path manipulation

    const UPLOAD_DIR = './uploads'; // Define your permanent upload directory

    export const handlePdfUpload = async (req, res) => {
      const user = runQuery("SELECT userId FROM userData WHERE email = ? LIMIT 1", [
        req.user.email,
      ]);

      if (!user) {
        return next(new ApiError(404, "User not found", [req.user.email])); // Use next(error)
      }

      let permanentFilePath; // Declare to ensure cleanup in catch

      try {
        logger.info("Uploaded file:", req.file);

        // Generate unique IDs for the document and a single chat session for it
        const documentId = uuidv4();
        const chatSessionId = uuidv4(); // One chat ID per document
        const originalFileName = req.file.originalname;
        const fileExtension = path.extname(originalFileName);
        const fileBaseName = path.basename(originalFileName, fileExtension);

        // Construct permanent file path
        await fs.mkdir(UPLOAD_DIR, { recursive: true }); // Ensure directory exists
        permanentFilePath = path.join(UPLOAD_DIR, `${documentId}${fileExtension}`);

        // Move the temporary file to permanent storage
        await fs.rename(req.file.path, permanentFilePath);
        logger.info(`File moved to permanent storage: ${permanentFilePath}`);

        // Insert document metadata into a 'documents' table (assuming new table or refactor of 'files')
        // Your current 'files' table needs to be adjusted. Let's assume a new table 'documents' for clarity.
        await runQuery(
          `INSERT INTO files (fileId, userId, filePath, originalFileName, fileSize, fileType, uploadedAt, chatId)
           VALUES (?, ?, ?, ?, ?, ?, ?, ?)`,
          [documentId, user.userId, permanentFilePath, originalFileName, req.file.size, req.file.mimetype, Date.now(), chatSessionId]
        );
        logger.info(`Document metadata inserted for documentId: ${documentId}`);

        // Chunk the PDF and process pages
        const pages = await chunkPdf(permanentFilePath);

        const addResults = await Promise.all(
          pages.map(async (page, index) => {
            const embedding = await getEmbeddings(page.pageContent);
            const vectorId = uuidv4(); // Unique ID for each vector

            // Add vector to ChromaDB, linking it to the documentId
            const vectorResult = await addVector({
              id: vectorId,
              embedding,
              userId: user.userId, // Pass userId for filtering in search
              text: page.pageContent,
              metadata: {
                documentId: documentId, // Link to the main document
                pageNumber: page.metadata.loc.pageNumber,
                chatId: chatSessionId, // Also link chat ID if needed for vector search
                // ... other metadata from page.metadata
              },
            });

            // Store vector metadata linked to the document in SQLite (if needed for managing vectors per document)
            // Example: If 'files' table represents vector chunks now
            // await runQuery(
            //   `INSERT INTO vectors (vectorId, documentId, pageNumber) VALUES (?, ?, ?)`,
            //   [vectorId, documentId, page.metadata.loc.pageNumber]
            // );
            return vectorResult.id;
          })
        );

        logger.info(`Added ${addResults.length} page vectors successfully for documentId: ${documentId}.`);

        // Respond to the client with the created file details
        return res.status(201).json({
          success: true,
          message: "PDF uploaded and processed successfully",
          file: { // Send comprehensive file data back to client
            fileId: documentId,
            name: originalFileName,
            type: req.file.mimetype,
            size: req.file.size,
            uploadedAt: formatTimestamp(new Date().toISOString()), // Use proper formatted time
          },
        });
      } catch (error) {
        logger.error("❌ Error in PDF upload handling:", error);
        // Clean up partially uploaded file if it was moved to permanent storage
        if (permanentFilePath) {
          try { await fs.unlink(permanentFilePath); logger.warn(`Cleaned up temporary file due to error: ${permanentFilePath}`); }
          catch (cleanupError) { logger.error(`Failed to clean up file ${permanentFilePath}:`, cleanupError); }
        }
        // Always pass errors to next() middleware in Express controllers
        return next(new ApiError(500, "Failed to process PDF upload", [error.message]));
      }
    };
    ```
    **Priority:** HIGH

**Line(s):** 71-76
-   **Issue Type:** LOGIC / MAINTAINABILITY
    **Description:** The `getUploadedFiles` endpoint currently only retrieves `fileId` and `filePath` from the `files` table. The client-side `Dashboard.jsx` (around line 199 and 240) expects more detailed file information like `name` (original filename), `type`, `size`, and `uploadTime` to display comprehensive file cards. This information is currently not stored in the `files` table and thus not retrieved, leading to incomplete UI data.
    **Line(s) to Fix:** 71-76
    **Current Code:**
    ```javascript
    const files = await runQuery(
      "SELECT fileId, filePath FROM files WHERE userId = ?",
      [user.userId]
    );
    ```
    **Suggested Fix:** The `files` table (or a new `documents` table as suggested in the previous point) should store `originalFileName`, `fileSize`, `uploadedAt`, `fileType`. The `getUploadedFiles` query should then select these additional columns, potentially aliasing them to match client expectations (`name`, `size`, `type`).

    ```javascript
    const files = await runQuery(
      // Assuming 'files' table now stores: fileId, userId, filePath, originalFileName, fileSize, fileType, uploadedAt, chatId
      `SELECT fileId, originalFileName AS name, fileSize AS size, fileType AS type, uploadedAt
       FROM files WHERE userId = ?`,
      [user.userId]
    );
    ```
    **Priority:** MEDIUM

**Line(s):** 89
-   **Issue Type:** BUG / LOGIC
    **Description:** The `deleteUploadedFiles` controller checks `if (!file)` to see if a file exists. However, `runQuery` with `SELECT ... WHERE ...` and `stmt.get()` (which is implied by `SELECT * ...`) returns `undefined` if no row is found, not an empty array. Therefore, `if (!file)` is the correct check. The debug `console.log(file);` should be removed.
    **Line(s) to Fix:** 89, 92
    **Current Code:**
    ```javascript
    if (!file) {
      throw new ApiError(404, "File not found", [fileId]);
    }
    //delete vectorIds from chroma db
    console.log(file);
    ```
    **Suggested Fix:** Remove the debug log. The `if (!file)` logic is correct.
    ```javascript
    if (!file) {
      throw new ApiError(404, "File not found", [fileId]);
    }
    // Remove: console.log(file);
    logger.info(`Deleting file record: ${fileId}. File details:`, file); // Use logger
    ```
    **Priority:** LOW

**File:** `server/src/controllers/user.controller.js`

**Line(s):** 19
-   **Issue Type:** STYLE / MAINTAINABILITY
    **Description:** `console.error("Error fetching chat history:", error);` is used for logging errors. For consistency and better production logging, all logging should go through the `logger` utility (already imported on line 2).
    **Line(s) to Fix:** 19
    **Current Code:** `console.error("Error fetching chat history:", error);`
    **Suggested Fix:**
    ```javascript
    logger.error("Error fetching chat history:", error);
    ```
    **Priority:** LOW

**File:** `server/src/database/chroma.db.js`

**Line(s)::** 7
-   **Issue Type:** SECURITY
    **Description:** The `apiKey` for ChromaDB is hardcoded directly in the source code (`"ck-CnDk3Frr5kzY6VjgF3nNaFLVTzjq7L8XnobPLBtn3bcR"`). This is a severe security vulnerability. Hardcoding credentials makes them easily discoverable, especially if the code is committed to a public repository or deployed insecurely. The `CHROMADB_API_KEY` is already imported (from `../../config/contants.js`, line 3) but not used.
    **Line(s) to Fix:** 7
    **Current Code:** `apiKey: "ck-CnDk3Frr5kzY6VjgF3nNaFLVTzjq7L8XnobPLBtn3bcR",`
    **Suggested Fix:** Use the imported environment variable `CHROMADB_API_KEY`.
    ```javascript
    apiKey: CHROMADB_API_KEY, // Use the imported API key from configuration
    ```
    **Priority:** HIGH

**Line(s):** 5-18, 59-61, 80-82
-   **Issue Type:** LOGIC / ERROR_HANDLING
    **Description:**
    1.  **`initChroma` (Lines 5-18):** The `initChroma` function lacks a `try...catch` block around the asynchronous operations (`new CloudClient` and `client.getOrCreateCollection`). If any of these operations fail (e.g., due to network issues, invalid credentials, or service unavailability), the promise returned by `initChroma` will reject, leading to an unhandled promise rejection that will crash the Node.js process when the top-level `await` is used (line 21).
    2.  **`addVector` (Lines 59-61):** The `catch` block for `addVector` only logs the error (`console.error`) but does not re-throw it or return an explicit error indicator. This leads to silent failures, where the `addVector` call might fail but the calling code (e.g., `upload.controller.js`) continues as if successful, leading to data inconsistencies.
    3.  **`deleteVector` (Lines 80-82):** Similar to `addVector`, the `catch` block for `deleteVector` only logs the error but does not re-throw or propagate it, leading to silent failures.
    **Line(s) to Fix:** 5-18, 59-61, 80-82
    **Current Code:**
    ```javascript
    // Lines 5-18 (initChroma)
    async function initChroma() {
      const client = new CloudClient({ /* ... */ });
      logger.info("ChromaDB CloudClient created.");
      const collection = await client.getOrCreateCollection({ /* ... */ });
      logger.info("ChromaDB collection ready.");
      return { client, collection };
    }
    // Lines 59-61 (addVector catch)
    } catch (error) {
      console.error("Error adding vector:", error);
    }
    // Lines 80-82 (deleteVector catch)
    } catch (error) {
      console.error("Error deleting vector:", error);
    }
    ```
    **Suggested Fix:** Implement `try...catch` blocks for all asynchronous operations and ensure errors are properly propagated (re-thrown).

    ```javascript
    import { CloudClient } from "chromadb";
    import { logger } from "../utils/logger.js";
    import { CHROMADB_API_KEY } from "../../config/contants.js"; // Correct the typo 'contants' to 'constants'

    async function initChroma() {
      try {
        const client = new CloudClient({
          apiKey: CHROMADB_API_KEY, // Use the environment variable
          tenant: "11489e26-4f87-43cf-9a04-80b0a61aa74e",
          database: "notebook-lm",
        });
        logger.info("ChromaDB CloudClient created.");

        const collection = await client.getOrCreateCollection({
          name: "notebook-lm",
        });
        logger.info("ChromaDB collection ready.");

        return { client, collection };
      } catch (error) {
        logger.error("Failed to initialize ChromaDB:", error.message || error);
        throw error; // Re-throw to propagate the error for higher-level handling
      }
    }

    export const addVector = async ({
      id,
      embedding,
      text,
      userId,
      metadata = {},
    }) => {
      // ... existing logic ...
      try {
        const res = await collection.add({
          ids: [id],
          documents: [String(text ?? "")],
          metadatas: [{ userId, ...flatMetadata }],
          embeddings: [vec],
        });
        console.log(res); // Consider removing or replacing with logger.debug

        return { id };
      } catch (error) {
        logger.error("Error adding vector to ChromaDB:", error); // Use logger
        throw new Error(`Failed to add vector: ${error.message}`); // Re-throw with a meaningful message
      }
    };

    // ... searchVector ...

    export const deleteVector = async (id) => {
      if (!id) {
        throw new Error("Vector ID is required for deletion");
      }
      try {
        const res = await collection.delete({
          ids: [id],
        });
        console.log("🗑️ Vector deleted:", res); // Consider removing or replacing with logger.info
        return res; // Return the result of deletion
      } catch (error) {
        logger.error("Error deleting vector from ChromaDB:", error); // Use logger
        throw new Error(`Failed to delete vector: ${error.message}`); // Re-throw
      }
    };

    // Consider adding a delete by documentId if that's the primary way files are managed
    /*
    export const deleteVectorsByDocumentId = async (documentId) => {
      if (!documentId) {
        throw new Error("Document ID is required for vector deletion");
      }
      try {
        // Assuming your vectors have 'documentId' in their metadata
        const res = await collection.delete({
          where: { documentId: { $eq: documentId } },
        });
        logger.info(`🗑️ Vectors for document ${documentId} deleted from ChromaDB:`, res);
        return res;
      } catch (error) {
        logger.error("Error deleting vectors by document ID from ChromaDB:", error);
        throw new Error(`Failed to delete vectors for document ${documentId}: ${error.message}`);
      }
    };
    */
    ```
    **Priority:** HIGH

**Line(s)::** 21
-   **Issue Type:** LOGIC / MAINTAINABILITY
    **Description:** Using top-level `await` for database initialization (`export const { client, collection } = await initChroma();`) is syntactically valid but can lead to immediate application termination if `initChroma` fails and throws an error (even with the `try-catch` added inside `initChroma`, the re-throw will still cause an unhandled rejection at this level if not caught). This makes it harder for the main application entry point to manage and report critical startup failures.
    **Line(s) to Fix:** 21
    **Current Code:** `export const { client, collection } = await initChroma();`
    **Suggested Fix:** Separate the export and initialization. Handle the promise rejection explicitly to control application startup.
    ```javascript
    let clientInstance;
    let collectionInstance;

    try {
      ({ client: clientInstance, collection: collectionInstance } = await initChroma());
    } catch (error) {
      logger.error("Application failed to initialize critical ChromaDB components. Exiting.", error);
      process.exit(1); // Exit if DB connection is critical for application startup
    }

    export const client = clientInstance;
    export const collection = collectionInstance;
    ```
    **Priority:** MEDIUM

**File:** `server/src/database/sqlLite.db.js`

**Line(s):** 4, 6
-   **Issue Type:** STYLE / DEBUG
    **Description:** `console.log` statements are used for debugging during database initialization. These should be replaced with the `logger` utility for consistent and configurable logging in production environments.
    **Line(s) to Fix:** 4, 6
    **Current Code:**
    ```javascript
    console.log("Initializing database...");
    export const db = new Database("./notebook-lm.sqlite");
    console.log(`Database path: ${db.name}`);
    ```
    **Suggested Fix:** Use `logger.info` instead.
    ```javascript
    import { logger } from "../utils/logger.js"; // Ensure logger is imported

    logger.info("Initializing database...");
    export const db = new Database("./notebook-lm.sqlite");
    logger.info(`Database path: ${db.name}`);
    ```
    **Priority:** LOW

**Line(s):** 20
-   **Issue Type:** STYLE / DEBUG
    **Description:** `console.log("Users table created or already exists.");` is a debug message that should be handled by the `logger` utility.
    **Line(s) to Fix:** 20
    **Current Code:** `console.log("Users table created or already exists.");`
    **Suggested Fix:**
    ```javascript
    logger.info("Users table created or already exists.");
    ```
    **Priority:** LOW

**Line(s):** 52
-   **Issue Type:** STYLE / DEBUG
    **Description:** The commented-out `//console.log(`Executing SQL: ${sql}`);` and `//console.log(stmt.run(params));` are debug statements that should be removed to keep the codebase clean.
    **Line(s) to Fix:** 52, 60
    **Current Code:**
    ```javascript
    //console.log(`Executing SQL: ${sql}`);
    // ...
    //console.log(stmt.run(params));
    ```
    **Suggested Fix:** Remove the commented-out lines. If needed, replace with `logger.debug`.
    ```javascript
    // Remove these lines
    ```
    **Priority:** LOW

**File:** `server/src/middlewares/auth.middleware.js`

**Line(s)::** 2
-   **Issue Type:** STYLE / MAINTAINABILITY
    **Description:** The import path `../../config/contants.js` contains a typo (`contants` instead of `constants`). While it might work due to file system tolerance, it's a spelling mistake and should be corrected.
    **Line(s) to Fix:** 2
    **Current Code:** `import { JWT_SECRET } from \"../../config/contants.js\";`
    **Suggested Fix:** Correct the typo.
    ```javascript
    import { JWT_SECRET } from "../../config/constants.js"; // Corrected typo
    ```
    **Priority:** MEDIUM

**Line(s):** 6, 14
-   **Issue Type:** STYLE / DEBUG
    **Description:** `console.log(token);` and `console.log("in mid", req.user);` are debug outputs. They should be removed from production code as they can add noise to server logs and potentially expose sensitive information (JWT token, user details).
    **Line(s) to Fix:** 6, 14
    **Current Code:**
    ```javascript
    console.log(token);
    // ...
    console.log("in mid", req.user);
    ```
    **Suggested Fix:** Remove the lines. If internal logging is needed, use `logger.debug`.
    ```javascript
    // Remove these lines
    ```
    **Priority:** LOW

**Line(s)::** 17-19
-   **Issue Type:** MAINTAINABILITY / LOGIC
    **Description:** When a token verification fails for reasons other than expiration, the server returns a generic \"Invalid token\" message. While this is good for security (not exposing internal errors), the actual `error` object contains valuable debugging information. Logging this error on the server-side (`console.error` or `logger.error`) will greatly assist in diagnosing and troubleshooting issues related to token validation without affecting the client's response.
    **Line(s) to Fix:** 17-19
    **Current Code:**
    ```javascript
    if (error.name === "TokenExpiredError") {
      return res.status(401).json({ success: false, error: "Token expired" });
    }
    return res.status(401).json({ success: false, error: "Invalid token" });
    ```
    **Suggested Fix:** Log the error details before sending a generic response.
    ```javascript
    if (error.name === "TokenExpiredError") {
      return res.status(401).json({ success: false, error: "Token expired" });
    }
    console.error("JWT verification failed:", error.message || error); // Log the actual error for server-side debugging
    return res.status(401).json({ success: false, error: "Invalid token" });
    ```
    **Priority:** MEDIUM

**File:** `server/src/routes/upload.route.js`

**Line(s):** 1-14
-   **Issue Type:** LOGIC / MAINTAINABILITY
    **Description:** The `upload.route.js` defines routes for upload, get files, and delete. The file does not include a route for downloading files, which is a required UI feature from `Dashboard.jsx`.
    **Line(s) to Fix:** N/A (requires adding a new route)
    **Current Code:**
    ```javascript
    import express from "express";
    import {
      handlePdfUpload,
      getUploadedFiles,
      deleteUploadedFiles,
    }
    from "../controllers/upload.controller.js";
    import { upload } from "../services/multer.service.js";
    import { verifyJwtToken } from "../middlewares/auth.middleware.js";

    const router = express.Router();

    router.post("/", verifyJwtToken, upload.single("pdfFile"), handlePdfUpload);
    router.get("/", verifyJwtToken, getUploadedFiles);
    router.delete("/:fileId", verifyJwtToken, deleteUploadedFiles);

    export default router;
    ```
    **Suggested Fix:** Add a `GET /download/:fileId` route and implement a corresponding controller function (`downloadFile`) in `upload.controller.js`.

    ```javascript
    import express from "express";
    import {
      handlePdfUpload,
      getUploadedFiles,
      deleteUploadedFiles,
      // Add this when implemented in controller:
      // downloadFile,
    } from "../controllers/upload.controller.js";
    import { upload } from "../services/multer.service.js";
    import { verifyJwtToken } from "../middlewares/auth.middleware.js";

    const router = express.Router();

    router.post("/", verifyJwtToken, upload.single("pdfFile"), handlePdfUpload);
    router.get("/", verifyJwtToken, getUploadedFiles);
    router.delete("/:fileId", verifyJwtToken, deleteUploadedFiles);
    // Add new route for download:
    // router.get("/download/:fileId", verifyJwtToken, downloadFile);

    export default router;
    ```
    **Priority:** MEDIUM

**File:** `server/src/routes/user.route.js`

**Line(s):** 9
-   **Issue Type:** SECURITY / LOGIC
    **Description:** The `router.get("/chatHistory", getChatHistory);` route is missing the `verifyJwtToken` middleware. This means any unauthenticated user can access the chat history of any user if they guess the `userId` or if it's implicitly derived from session, which is a significant security vulnerability. All user-specific data endpoints should be protected.
    **Line(s) to Fix:** 9
    **Current Code:** `router.get(\"/chatHistory\", getChatHistory);`
    **Suggested Fix:** Add the `verifyJwtToken` middleware to this route.
    ```javascript
    router.get("/chatHistory", verifyJwtToken, getChatHistory);
    ```
    **Priority:** HIGH

**File:** `server/src/services/chromadb.service.js`

**Line(s):** 2
-   **Issue Type:** STYLE / MAINTAINABILITY
    **Description:** The `uuid` import is aliased as `uuid` (`import { v4 as uuid } from \"uuid\";`), but used as `uuidv4()` in `upload.controller.js`. While this doesn't cause a crash (as `uuid` is the `v4` function), it's inconsistent and can be confusing. It's better to stick to one naming convention or alias it to `uuidv4` if that's the preferred usage.
    **Line(s) to Fix:** 2
    **Current Code:** `import { v4 as uuid } from \"uuid\";`
    **Suggested Fix:** Alias it consistently.
    ```javascript
    import { v4 as uuidv4 } from "uuid"; // Use uuidv4 consistently
    ```
    **Priority:** LOW

**Line(s)::** 36-37
-   **Issue Type:** BUG / LOGIC
    **Description:** The `normalizeEmbedding` function validates that all elements are `number` and `Number.isFinite`. However, it doesn't explicitly handle the case where the normalized `emb` array ends up being empty. ChromaDB embeddings are typically expected to have a specific, non-zero dimension. An empty array `[]` would pass `!Array.isArray(emb)` (false) and `!emb.every(...)` (false because `every` on empty array returns true), potentially leading to errors or unexpected behavior when passed to `collection.add`.
    **Line(s) to Fix:** 36-37
    **Current Code:**
    ```javascript
    if (!Array.isArray(emb)) {
      throw new TypeError("embedding must be an array");
    }
    if (!emb.every((x) => typeof x === "number" && Number.isFinite(x))) {
      throw new TypeError("embedding contains non-numeric values");
    }
    return emb;
    ```
    **Suggested Fix:** Add a check to ensure the embedding array is not empty.
    ```javascript
    if (!Array.isArray(emb)) {
      throw new TypeError("embedding must be an array");
    }
    if (emb.length === 0) { // Added check for empty array
      throw new TypeError("embedding cannot be empty");
    }
    if (!emb.every((x) => typeof x === "number" && Number.isFinite(x))) {
      throw new TypeError("embedding contains non-numeric values");
    }
    return emb;
    ```
    **Priority:** MEDIUM

**Line(s):** 65
-   **Issue Type:** STYLE / DEBUG
    **Description:** `console.log(res);` in `addVector` is a debug statement that should be removed from production code.
    **Line(s) to Fix:** 65
    **Current Code:** `console.log(res);`
    **Suggested Fix:** Remove the line or replace with `logger.debug(res)`.
    ```javascript
    // Remove this line
    ```
    **Priority:** LOW

**Line(s):** 71-73
-   **Issue Type:** LOGIC / CONSISTENCY
    **Description:** The validation logic for `embedding` in `searchVector` (`!embedding.every((x) => typeof x === "number")`) is less strict than the `normalizeEmbedding` function, which additionally checks for `Number.isFinite(x)`. Passing `NaN` or `Infinity` values could lead to unexpected behavior or errors in ChromaDB. For consistency and robustness, `searchVector` should validate embeddings with the same rigor as `addVector`. The best approach is to reuse `normalizeEmbedding`.
    **Line(s) to Fix:** 71-73
    **Current Code:**
    ```javascript
    if (
      !Array.isArray(embedding) ||
      !embedding.every((x) => typeof x === "number")
    ) {
      throw new Error("Invalid embedding: must be an array of numbers");
    }
    ```
    **Suggested Fix:** Reuse `normalizeEmbedding` for consistent validation and normalization.
    ```javascript
    export const searchVector = async (embedding, userId, n_results = 2) => {
      const queryEmbedding = normalizeEmbedding(embedding); // Use normalizeEmbedding

      return await collection.query({
        queryEmbeddings: [queryEmbedding], // Use the normalized embedding
        n_results,
        where: { userId: { $eq: userId } },
      });
    };
    ```
    **Priority:** HIGH

**Line(s):** 90
-   **Issue Type:** STYLE / DEBUG
    **Description:** `console.log("🗑️ Vector deleted:", res);` is a debug statement that should be removed from production code.
    **Line(s) to Fix:** 90
    **Current Code:** `console.log(\"🗑️ Vector deleted:\", res);`
    **Suggested Fix:** Remove the line or replace with `logger.info("Vector deleted:", res)`.
    ```javascript
    // Remove this line
    ```
    **Priority:** LOW

**File:** `server/src/utils/jwtMaker.js`

**Line(s)::** 22
-   **Issue Type:** BUG / LOGIC
    **Description:** The `createJwtToken` function is currently written to accept two separate arguments (`userEmail`, `userId`), but the `auth.controller.js` file (lines 40, 75) calls it by passing `email` and `newUser.lastInsertRowid` / `user[0].userId`.
    The `accessTokenPayload` and `refreshTokenPayload` objects within `createJwtToken` are defined with keys `email` and `userId`. This implies the function expects a single object argument (e.g., `{ email, userId }`) that contains these properties. The current signature `(userEmail, userId)` means `userEmail` becomes the entire payload, which is incorrect and results in JWTs with a malformed payload.
    **Line(s) to Fix:** 4
    **Current Code:** `export const createJwtToken = (userEmail, userId) => {`
    **Suggested Fix:** Adjust the function signature to accept a single payload object, or destructure the expected properties directly.
    ```javascript
    export const createJwtToken = (payload) => { // Accept single payload object
      const accessTokenPayload = {
        email: payload.email, // Access properties from the payload object
        userId: payload.userId,
        type: "access",
      };

      const refreshTokenPayload = {
        email: payload.email,
        userId: payload.userId,
        type: "refresh",
      };
    // ... rest of the function ...
    };
    ```
    **Priority:** HIGH

**Line(s):** 28
-   **Issue Type:** BUG / LOGIC
    **Description:** The line `//return token;` is commented out, but its presence suggests it might have been a previous attempt or a misunderstanding. More importantly, it directly follows `return { accessToken, refreshToken };` on line 27. If it were uncommented, it would be unreachable code. If `token` was intended to be a single string, the function's logic needs to be revised as it currently returns an object.
    **Line(s) to Fix:** 28
    **Current Code:** `//return token;`
    **Suggested Fix:** Remove the commented-out line.
    ```javascript
    // Remove this line
    ```
    **Priority:** LOW

**Line(s):** 29-31
-   **Issue Type:** LOGIC / MAINTAINABILITY
    **Description:** The `catch` block for the `jwt.sign` operation only logs the error to the console (`console.log(error);`) but does not re-throw it or return an explicit error indicator. This means that if token creation fails for any reason, the `createJwtToken` function will implicitly return `undefined` to its caller without signaling the failure. This can lead to silent failures and hard-to-debug issues elsewhere in the application (e.g., in `auth.controller.js`, where it expects valid tokens).
    **Line(s) to Fix:** 29-31
    **Current Code:**
    ```javascript
    } catch (error) {
      console.log(error);
    }
    ```
    **Suggested Fix:** Re-throw the error to ensure calling functions handle the failure explicitly. Use `console.error` for errors.
    ```javascript
    } catch (error) {
      console.error("Error creating JWT token:", error); // Use console.error for errors
      throw error; // Re-throw the error to ensure calling functions handle the failure
      // Alternatively, return null; if caller is designed to check for null return.
    }
    ```
    **Priority:** HIGH